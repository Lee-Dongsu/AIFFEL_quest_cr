{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제. 0\n",
    "\n",
    "원인:\n",
    "PositionalEncoding 레이어에서 SparseTensor를 연산하려고 할 때 발생하는 문제입니다. \n",
    "\n",
    "해결:\n",
    "데이터셋 변환 시 Dense 보장 (모델에 들어가는 입력이 SparseTensor로 변환되지 않도록 보장하는 것)\n",
    "Input Layer에서 명시적으로 sparse=False 지정\n",
    "PositionalEncoding 내부에서 처리 (비추천) <- 이건 적용안함\n",
    "\n",
    "문제. 1\n",
    "\n",
    "원인:\n",
    "tf.sparse.is_sparse() 라는 함수나 속성이 TensorFlow 2.x에서 더 이상 제공되지 않는 것에서 비롯됩니다. \n",
    "과거 TensorFlow 1.x에서는 tf.sparse.is_sparse()가 존재했지만, 2.x에서는 이를 사용할 수 없습니다.\n",
    "대신, TensorFlow에서는 tf.sparse 모듈 내 연산을 사용하려면 주어진 텐서가 tf.SparseTensor 타입인지 직접 확인하는 방식을 사용합니다.\n",
    "\n",
    "해결:\n",
    "tf.sparse.is_sparse()는 사용 불가능합니다.\n",
    "대신 isinstance(tensor, tf.SparseTensor)를 사용하여 SparseTensor 여부를 확인합니다.\n",
    "이를 통해 SparseTensor일 경우 tf.sparse.to_dense()로 변환하는 로직을 적용했습니다.\n",
    "\n",
    "문제. 2\n",
    "\n",
    "원인:\n",
    "해당 오류는 실제 y_true(타겟)와 y_pred(모델 출력)의 시퀀스 길이 차이에서 비롯됩니다. 에러 메시지를 자세히 보면 다음과 같습니다.\n",
    "39 , 40 문제.\n",
    "\n",
    "해결:\n",
    "loss_function에서 불필요한 reshape 제거\n",
    "dec_inputs와 outputs의 길이가 39로 동일하게 유지되는지 확인\n",
    "필요하다면 loss_function 내에서 y_pred를 y_true 길이에 맞게 슬라이싱 (임시 방편)\n",
    "\n",
    "문제. 3\n",
    "\n",
    "원인:\n",
    "현재 CustomSchedule 클래스의 __call__ 메서드에서 step은 int64 형태로 들어옵니다.\n",
    "tf.math.rsqrt 및 tf.math.minimum 등 부동소수점 연산은 float형 입력을 기대합니다.\n",
    "따라서 step을 float32로 캐스팅해줘야 합니다.\n",
    "\n",
    "해결:\n",
    "CustomSchedule 클래스의 __call__ 메서드에서 step을 tf.cast(step, tf.float32)로 변환함으로써 int64에서 float32 타입으로 맞춰주었습니다.\n",
    "이로써 tf.math.rsqrt 함수 호출 시 데이터 타입 문제를 해결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823\n",
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n",
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n",
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n",
      "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장: 가스비 비싼데 감기 걸리겠어\n",
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n",
      "질문 데이터 shape: (11823, 40)\n",
      "답변 데이터 shape: (11823, 40)\n",
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_padding_mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,148,288</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ enc_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ look_ahead_mask     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_padding_mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,675,648</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ look_ahead_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ dec_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,102,260</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8180</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_padding_mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,148,288\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ enc_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ look_ahead_mask     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_padding_mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,675,648\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ look_ahead_mask[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ dec_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m2,102,260\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m8180\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,926,196</span> (34.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,926,196\u001b[0m (34.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,926,196</span> (34.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,926,196\u001b[0m (34.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 485ms/step - accuracy: 0.0122 - loss: 1.5213\n",
      "Epoch 2/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.0258 - loss: 1.2581\n",
      "Epoch 3/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.0387 - loss: 1.0494\n",
      "Epoch 4/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.0554 - loss: 0.9170\n",
      "Epoch 5/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 469ms/step - accuracy: 0.0706 - loss: 0.7966\n",
      "Epoch 6/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 484ms/step - accuracy: 0.0878 - loss: 0.6360\n",
      "Epoch 7/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 482ms/step - accuracy: 0.1062 - loss: 0.4841\n",
      "Epoch 8/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 486ms/step - accuracy: 0.1277 - loss: 0.3579\n",
      "Epoch 9/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 465ms/step - accuracy: 0.1480 - loss: 0.2449\n",
      "Epoch 10/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 455ms/step - accuracy: 0.1627 - loss: 0.1601\n",
      "Epoch 11/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 453ms/step - accuracy: 0.1680 - loss: 0.0951\n",
      "Epoch 12/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 451ms/step - accuracy: 0.1707 - loss: 0.0590\n",
      "Epoch 13/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 448ms/step - accuracy: 0.1711 - loss: 0.0391\n",
      "Epoch 14/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 447ms/step - accuracy: 0.1728 - loss: 0.0248\n",
      "Epoch 15/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 447ms/step - accuracy: 0.1718 - loss: 0.0188\n",
      "Epoch 16/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 449ms/step - accuracy: 0.1715 - loss: 0.0250\n",
      "Epoch 17/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 453ms/step - accuracy: 0.1723 - loss: 0.0199\n",
      "Epoch 18/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 456ms/step - accuracy: 0.1725 - loss: 0.0223\n",
      "Epoch 19/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 458ms/step - accuracy: 0.1712 - loss: 0.0238\n",
      "Epoch 20/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 457ms/step - accuracy: 0.1709 - loss: 0.0211\n",
      "Epoch 21/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 458ms/step - accuracy: 0.1716 - loss: 0.0220\n",
      "Epoch 22/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 444ms/step - accuracy: 0.1705 - loss: 0.0244\n",
      "Epoch 23/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 444ms/step - accuracy: 0.1704 - loss: 0.0242\n",
      "Epoch 24/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1713 - loss: 0.0216\n",
      "Epoch 25/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 448ms/step - accuracy: 0.1711 - loss: 0.0183\n",
      "Epoch 26/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1719 - loss: 0.0175\n",
      "Epoch 27/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1702 - loss: 0.0192\n",
      "Epoch 28/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1718 - loss: 0.0140\n",
      "Epoch 29/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 445ms/step - accuracy: 0.1714 - loss: 0.0188\n",
      "Epoch 30/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1734 - loss: 0.0178\n",
      "Epoch 31/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1723 - loss: 0.0159\n",
      "Epoch 32/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1720 - loss: 0.0127\n",
      "Epoch 33/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1722 - loss: 0.0134\n",
      "Epoch 34/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1728 - loss: 0.0139\n",
      "Epoch 35/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1735 - loss: 0.0101\n",
      "Epoch 36/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1737 - loss: 0.0123\n",
      "Epoch 37/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 440ms/step - accuracy: 0.1734 - loss: 0.0109\n",
      "Epoch 38/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1725 - loss: 0.0101\n",
      "Epoch 39/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1725 - loss: 0.0096\n",
      "Epoch 40/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1730 - loss: 0.0110\n",
      "Epoch 41/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1737 - loss: 0.0085\n",
      "Epoch 42/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1722 - loss: 0.0098\n",
      "Epoch 43/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 446ms/step - accuracy: 0.1732 - loss: 0.0085\n",
      "Epoch 44/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 446ms/step - accuracy: 0.1735 - loss: 0.0089\n",
      "Epoch 45/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 446ms/step - accuracy: 0.1734 - loss: 0.0071\n",
      "Epoch 46/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1729 - loss: 0.0069\n",
      "Epoch 47/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 449ms/step - accuracy: 0.1743 - loss: 0.0080\n",
      "Epoch 48/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 445ms/step - accuracy: 0.1734 - loss: 0.0089\n",
      "Epoch 49/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1729 - loss: 0.0079\n",
      "Epoch 50/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1733 - loss: 0.0091\n",
      "Epoch 51/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1728 - loss: 0.0067\n",
      "Epoch 52/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1742 - loss: 0.0077\n",
      "Epoch 53/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1732 - loss: 0.0074\n",
      "Epoch 54/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1731 - loss: 0.0066\n",
      "Epoch 55/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1742 - loss: 0.0059\n",
      "Epoch 56/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1725 - loss: 0.0070\n",
      "Epoch 57/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1737 - loss: 0.0067\n",
      "Epoch 58/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1736 - loss: 0.0072\n",
      "Epoch 59/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 444ms/step - accuracy: 0.1743 - loss: 0.0064\n",
      "Epoch 60/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1737 - loss: 0.0074\n",
      "Epoch 61/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1737 - loss: 0.0054\n",
      "Epoch 62/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1749 - loss: 0.0053\n",
      "Epoch 63/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1737 - loss: 0.0067\n",
      "Epoch 64/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1743 - loss: 0.0067\n",
      "Epoch 65/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1742 - loss: 0.0052\n",
      "Epoch 66/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 445ms/step - accuracy: 0.1745 - loss: 0.0052\n",
      "Epoch 67/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 445ms/step - accuracy: 0.1730 - loss: 0.0054\n",
      "Epoch 68/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 446ms/step - accuracy: 0.1744 - loss: 0.0046\n",
      "Epoch 69/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 446ms/step - accuracy: 0.1747 - loss: 0.0054\n",
      "Epoch 70/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 444ms/step - accuracy: 0.1736 - loss: 0.0047\n",
      "Epoch 71/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 448ms/step - accuracy: 0.1730 - loss: 0.0044\n",
      "Epoch 72/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 446ms/step - accuracy: 0.1737 - loss: 0.0045\n",
      "Epoch 73/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 446ms/step - accuracy: 0.1739 - loss: 0.0058\n",
      "Epoch 74/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 445ms/step - accuracy: 0.1732 - loss: 0.0047\n",
      "Epoch 75/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 445ms/step - accuracy: 0.1739 - loss: 0.0051\n",
      "Epoch 76/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1745 - loss: 0.0046\n",
      "Epoch 77/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 441ms/step - accuracy: 0.1740 - loss: 0.0051\n",
      "Epoch 78/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 442ms/step - accuracy: 0.1739 - loss: 0.0048\n",
      "Epoch 79/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 446ms/step - accuracy: 0.1732 - loss: 0.0046\n",
      "Epoch 80/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 445ms/step - accuracy: 0.1735 - loss: 0.0043\n",
      "Epoch 81/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 443ms/step - accuracy: 0.1736 - loss: 0.0045\n",
      "Epoch 82/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 444ms/step - accuracy: 0.1746 - loss: 0.0034\n",
      "Epoch 83/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 464ms/step - accuracy: 0.1745 - loss: 0.0042\n",
      "Epoch 84/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 475ms/step - accuracy: 0.1748 - loss: 0.0033\n",
      "Epoch 85/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 481ms/step - accuracy: 0.1744 - loss: 0.0042\n",
      "Epoch 86/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 485ms/step - accuracy: 0.1735 - loss: 0.0040\n",
      "Epoch 87/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 484ms/step - accuracy: 0.1743 - loss: 0.0034\n",
      "Epoch 88/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 485ms/step - accuracy: 0.1744 - loss: 0.0041\n",
      "Epoch 89/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 488ms/step - accuracy: 0.1734 - loss: 0.0045\n",
      "Epoch 90/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 485ms/step - accuracy: 0.1744 - loss: 0.0034\n",
      "Epoch 91/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 490ms/step - accuracy: 0.1738 - loss: 0.0038\n",
      "Epoch 92/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 489ms/step - accuracy: 0.1742 - loss: 0.0034\n",
      "Epoch 93/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 487ms/step - accuracy: 0.1744 - loss: 0.0037\n",
      "Epoch 94/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 489ms/step - accuracy: 0.1744 - loss: 0.0034\n",
      "Epoch 95/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 492ms/step - accuracy: 0.1738 - loss: 0.0025\n",
      "Epoch 96/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 491ms/step - accuracy: 0.1744 - loss: 0.0031\n",
      "Epoch 97/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 491ms/step - accuracy: 0.1738 - loss: 0.0035\n",
      "Epoch 98/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 503ms/step - accuracy: 0.1742 - loss: 0.0030\n",
      "Epoch 99/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 511ms/step - accuracy: 0.1754 - loss: 0.0034\n",
      "Epoch 100/100\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 501ms/step - accuracy: 0.1736 - loss: 0.0032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c1950a3580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "\n",
    "print('챗봇 샘플의 개수 :', len(train_data))\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)\n",
    "\n",
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "\n",
    "# 서브워드 텍스트 인코더로 단어 집합 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))\n",
    "\n",
    "sample_string = questions[20]\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))\n",
    "\n",
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "\n",
    "print('질문 데이터 shape:', questions.shape)\n",
    "print('답변 데이터 shape:', answers.shape)\n",
    "print(questions[0])\n",
    "print(answers[0])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]  # (batch, 39)\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]      # (batch, 39)\n",
    "    },\n",
    "))\n",
    "\n",
    "def to_dense_if_sparse(x):\n",
    "    return tf.sparse.to_dense(x) if isinstance(x, tf.SparseTensor) else x\n",
    "\n",
    "dataset = dataset.map(lambda x, y: (\n",
    "    {\n",
    "        'inputs': to_dense_if_sparse(x['inputs']),\n",
    "        'dec_inputs': to_dense_if_sparse(x['dec_inputs'])\n",
    "    },\n",
    "    {\n",
    "        'outputs': to_dense_if_sparse(y['outputs'])\n",
    "    }\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(answers[0])\n",
    "print(answers[:1][:, :-1])\n",
    "print(answers[:1][:, 1:])\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding, [1, 2, 0])\n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if isinstance(inputs, tf.SparseTensor):\n",
    "        inputs = tf.sparse.to_dense(inputs)\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    assert d_model % self.num_heads == 0\n",
    "    self.depth = d_model // self.num_heads\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "    concat_attention = tf.reshape(scaled_attention,(batch_size, -1, self.d_model))\n",
    "    outputs = self.dense(concat_attention)\n",
    "    return outputs\n",
    "\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")({\n",
    "      'query': inputs, 'key': inputs, 'value': inputs, 'mask': padding_mask\n",
    "  })\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\", dtype=tf.int32)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(MAX_LENGTH, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(units=units,\n",
    "                            d_model=d_model,\n",
    "                            num_heads=num_heads,\n",
    "                            dropout=dropout,\n",
    "                            name=\"encoder_layer_{}\".format(i))([outputs, padding_mask])\n",
    "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "      'query': inputs, 'key': inputs, 'value': inputs, 'mask': look_ahead_mask\n",
    "  })\n",
    "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "  attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "      'query': attention1, 'key': enc_outputs, 'value': enc_outputs, 'mask': padding_mask\n",
    "  })\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "\n",
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs', dtype=tf.int32)\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(MAX_LENGTH, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(units=units,\n",
    "                            d_model=d_model,\n",
    "                            num_heads=num_heads,\n",
    "                            dropout=dropout,\n",
    "                            name='decoder_layer_{}'.format(i))(\n",
    "                              [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\", dtype=tf.int32)\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\", dtype=tf.int32)\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_pred = y_pred[:, :tf.shape(y_true)[1], :]\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "# 여기서 step이 int64 -> float32 캐스팅 필요\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = tf.cast(d_model, tf.float32)\n",
    "    self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)  # int64를 float32로 변환\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_pred = y_pred[:, :tf.shape(y_true)[1], :]\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "EPOCHS = 100\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  # 단어와 구두점 사이에 공백 추가.\n",
    "  # ex) 12시 땡! -> 12시 땡 !\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  # 입력 문장에 대한 전처리\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
    "    # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  # 단어 예측이 모두 끝났다면 output을 리턴.\n",
    "  return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
    "  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 영화 볼래?\n",
      "Output: 영화 볼 ? ?\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"영화 볼래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 고민이 있어\n",
      "Output: 고민이 있어\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너무 화가나\n",
      "Output: 너무 잘 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 이번 주말에 어디를 놀러가면 좋을까?\n",
      "Output: 이번 주말에 어디를  .면  ? ?\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"이번 주말에 어디를 놀러가면 좋을까?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
