{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRm-USlsHgEV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pytorch-CycleGAN-and-pix2pix' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1EySlOXwwoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.9.1+cu111)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.10.1+cu111)\n",
      "Requirement already satisfied: dominate>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.9.1)\n",
      "Requirement already satisfied: visdom>=0.1.8.8 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.2.4)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.18.7)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.4)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (8.3.2)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.2.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.6.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.26.0)\n",
      "Requirement already satisfied: jsonpatch in /opt/conda/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: tornado in /opt/conda/lib/python3.9/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (3.19.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (1.3.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (8.0.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (2.19.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (6.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (5.8.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 5)) (59.4.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.26.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2021.10.8)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.9/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified [facades]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2024-12-01 12:19:59--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30168306 (29M) [application/x-gzip]\n",
      "Saving to: ‘./datasets/facades.tar.gz’\n",
      "\n",
      "./datasets/facades. 100%[===================>]  28.77M  4.40MB/s    in 7.4s    \n",
      "\n",
      "2024-12-01 12:20:06 (3.90 MB/s) - ‘./datasets/facades.tar.gz’ saved [30168306/30168306]\n",
      "\n",
      "facades/\n",
      "facades/test/\n",
      "facades/test/27.jpg\n",
      "facades/test/5.jpg\n",
      "facades/test/72.jpg\n",
      "facades/test/1.jpg\n",
      "facades/test/10.jpg\n",
      "facades/test/100.jpg\n",
      "facades/test/101.jpg\n",
      "facades/test/102.jpg\n",
      "facades/test/103.jpg\n",
      "facades/test/104.jpg\n",
      "facades/test/105.jpg\n",
      "facades/test/106.jpg\n",
      "facades/test/11.jpg\n",
      "facades/test/12.jpg\n",
      "facades/test/13.jpg\n",
      "facades/test/14.jpg\n",
      "facades/test/15.jpg\n",
      "facades/test/16.jpg\n",
      "facades/test/17.jpg\n",
      "facades/test/18.jpg\n",
      "facades/test/19.jpg\n",
      "facades/test/2.jpg\n",
      "facades/test/20.jpg\n",
      "facades/test/21.jpg\n",
      "facades/test/22.jpg\n",
      "facades/test/23.jpg\n",
      "facades/test/24.jpg\n",
      "facades/test/25.jpg\n",
      "facades/test/26.jpg\n",
      "facades/test/50.jpg\n",
      "facades/test/51.jpg\n",
      "facades/test/52.jpg\n",
      "facades/test/53.jpg\n",
      "facades/test/54.jpg\n",
      "facades/test/55.jpg\n",
      "facades/test/56.jpg\n",
      "facades/test/57.jpg\n",
      "facades/test/58.jpg\n",
      "facades/test/59.jpg\n",
      "facades/test/6.jpg\n",
      "facades/test/60.jpg\n",
      "facades/test/61.jpg\n",
      "facades/test/62.jpg\n",
      "facades/test/63.jpg\n",
      "facades/test/64.jpg\n",
      "facades/test/65.jpg\n",
      "facades/test/66.jpg\n",
      "facades/test/67.jpg\n",
      "facades/test/68.jpg\n",
      "facades/test/69.jpg\n",
      "facades/test/7.jpg\n",
      "facades/test/70.jpg\n",
      "facades/test/71.jpg\n",
      "facades/test/73.jpg\n",
      "facades/test/74.jpg\n",
      "facades/test/75.jpg\n",
      "facades/test/76.jpg\n",
      "facades/test/77.jpg\n",
      "facades/test/78.jpg\n",
      "facades/test/79.jpg\n",
      "facades/test/8.jpg\n",
      "facades/test/80.jpg\n",
      "facades/test/81.jpg\n",
      "facades/test/82.jpg\n",
      "facades/test/83.jpg\n",
      "facades/test/84.jpg\n",
      "facades/test/85.jpg\n",
      "facades/test/86.jpg\n",
      "facades/test/87.jpg\n",
      "facades/test/88.jpg\n",
      "facades/test/89.jpg\n",
      "facades/test/9.jpg\n",
      "facades/test/90.jpg\n",
      "facades/test/91.jpg\n",
      "facades/test/92.jpg\n",
      "facades/test/93.jpg\n",
      "facades/test/94.jpg\n",
      "facades/test/95.jpg\n",
      "facades/test/96.jpg\n",
      "facades/test/97.jpg\n",
      "facades/test/98.jpg\n",
      "facades/test/99.jpg\n",
      "facades/test/28.jpg\n",
      "facades/test/29.jpg\n",
      "facades/test/3.jpg\n",
      "facades/test/30.jpg\n",
      "facades/test/31.jpg\n",
      "facades/test/32.jpg\n",
      "facades/test/33.jpg\n",
      "facades/test/34.jpg\n",
      "facades/test/35.jpg\n",
      "facades/test/36.jpg\n",
      "facades/test/37.jpg\n",
      "facades/test/38.jpg\n",
      "facades/test/39.jpg\n",
      "facades/test/4.jpg\n",
      "facades/test/40.jpg\n",
      "facades/test/41.jpg\n",
      "facades/test/42.jpg\n",
      "facades/test/43.jpg\n",
      "facades/test/44.jpg\n",
      "facades/test/45.jpg\n",
      "facades/test/46.jpg\n",
      "facades/test/47.jpg\n",
      "facades/test/48.jpg\n",
      "facades/test/49.jpg\n",
      "facades/train/\n",
      "facades/train/1.jpg\n",
      "facades/train/10.jpg\n",
      "facades/train/100.jpg\n",
      "facades/train/101.jpg\n",
      "facades/train/102.jpg\n",
      "facades/train/103.jpg\n",
      "facades/train/104.jpg\n",
      "facades/train/105.jpg\n",
      "facades/train/106.jpg\n",
      "facades/train/107.jpg\n",
      "facades/train/108.jpg\n",
      "facades/train/109.jpg\n",
      "facades/train/11.jpg\n",
      "facades/train/110.jpg\n",
      "facades/train/111.jpg\n",
      "facades/train/112.jpg\n",
      "facades/train/113.jpg\n",
      "facades/train/114.jpg\n",
      "facades/train/115.jpg\n",
      "facades/train/116.jpg\n",
      "facades/train/117.jpg\n",
      "facades/train/118.jpg\n",
      "facades/train/119.jpg\n",
      "facades/train/12.jpg\n",
      "facades/train/120.jpg\n",
      "facades/train/121.jpg\n",
      "facades/train/122.jpg\n",
      "facades/train/123.jpg\n",
      "facades/train/124.jpg\n",
      "facades/train/125.jpg\n",
      "facades/train/126.jpg\n",
      "facades/train/309.jpg\n",
      "facades/train/31.jpg\n",
      "facades/train/310.jpg\n",
      "facades/train/311.jpg\n",
      "facades/train/312.jpg\n",
      "facades/train/313.jpg\n",
      "facades/train/314.jpg\n",
      "facades/train/315.jpg\n",
      "facades/train/316.jpg\n",
      "facades/train/317.jpg\n",
      "facades/train/318.jpg\n",
      "facades/train/319.jpg\n",
      "facades/train/32.jpg\n",
      "facades/train/320.jpg\n",
      "facades/train/321.jpg\n",
      "facades/train/322.jpg\n",
      "facades/train/323.jpg\n",
      "facades/train/324.jpg\n",
      "facades/train/325.jpg\n",
      "facades/train/326.jpg\n",
      "facades/train/327.jpg\n",
      "facades/train/328.jpg\n",
      "facades/train/329.jpg\n",
      "facades/train/390.jpg\n",
      "facades/train/391.jpg\n",
      "facades/train/392.jpg\n",
      "facades/train/393.jpg\n",
      "facades/train/394.jpg\n",
      "facades/train/395.jpg\n",
      "facades/train/396.jpg\n",
      "facades/train/397.jpg\n",
      "facades/train/398.jpg\n",
      "facades/train/399.jpg\n",
      "facades/train/4.jpg\n",
      "facades/train/40.jpg\n",
      "facades/train/400.jpg\n",
      "facades/train/41.jpg\n",
      "facades/train/42.jpg\n",
      "facades/train/43.jpg\n",
      "facades/train/44.jpg\n",
      "facades/train/45.jpg\n",
      "facades/train/46.jpg\n",
      "facades/train/47.jpg\n",
      "facades/train/48.jpg\n",
      "facades/train/49.jpg\n",
      "facades/train/5.jpg\n",
      "facades/train/50.jpg\n",
      "facades/train/51.jpg\n",
      "facades/train/52.jpg\n",
      "facades/train/53.jpg\n",
      "facades/train/54.jpg\n",
      "facades/train/55.jpg\n",
      "facades/train/56.jpg\n",
      "facades/train/57.jpg\n",
      "facades/train/58.jpg\n",
      "facades/train/59.jpg\n",
      "facades/train/6.jpg\n",
      "facades/train/60.jpg\n",
      "facades/train/61.jpg\n",
      "facades/train/222.jpg\n",
      "facades/train/223.jpg\n",
      "facades/train/224.jpg\n",
      "facades/train/225.jpg\n",
      "facades/train/226.jpg\n",
      "facades/train/227.jpg\n",
      "facades/train/228.jpg\n",
      "facades/train/229.jpg\n",
      "facades/train/23.jpg\n",
      "facades/train/230.jpg\n",
      "facades/train/231.jpg\n",
      "facades/train/232.jpg\n",
      "facades/train/233.jpg\n",
      "facades/train/234.jpg\n",
      "facades/train/235.jpg\n",
      "facades/train/236.jpg\n",
      "facades/train/237.jpg\n",
      "facades/train/238.jpg\n",
      "facades/train/239.jpg\n",
      "facades/train/24.jpg\n",
      "facades/train/240.jpg\n",
      "facades/train/241.jpg\n",
      "facades/train/242.jpg\n",
      "facades/train/243.jpg\n",
      "facades/train/244.jpg\n",
      "facades/train/245.jpg\n",
      "facades/train/156.jpg\n",
      "facades/train/157.jpg\n",
      "facades/train/158.jpg\n",
      "facades/train/159.jpg\n",
      "facades/train/16.jpg\n",
      "facades/train/160.jpg\n",
      "facades/train/161.jpg\n",
      "facades/train/162.jpg\n",
      "facades/train/163.jpg\n",
      "facades/train/164.jpg\n",
      "facades/train/165.jpg\n",
      "facades/train/166.jpg\n",
      "facades/train/167.jpg\n",
      "facades/train/168.jpg\n",
      "facades/train/169.jpg\n",
      "facades/train/17.jpg\n",
      "facades/train/170.jpg\n",
      "facades/train/171.jpg\n",
      "facades/train/172.jpg\n",
      "facades/train/173.jpg\n",
      "facades/train/174.jpg\n",
      "facades/train/175.jpg\n",
      "facades/train/176.jpg\n",
      "facades/train/177.jpg\n",
      "facades/train/178.jpg\n",
      "facades/train/179.jpg\n",
      "facades/train/18.jpg\n",
      "facades/train/180.jpg\n",
      "facades/train/181.jpg\n",
      "facades/train/182.jpg\n",
      "facades/train/183.jpg\n",
      "facades/train/184.jpg\n",
      "facades/train/185.jpg\n",
      "facades/train/186.jpg\n",
      "facades/train/187.jpg\n",
      "facades/train/188.jpg\n",
      "facades/train/189.jpg\n",
      "facades/train/19.jpg\n",
      "facades/train/127.jpg\n",
      "facades/train/155.jpg\n",
      "facades/train/190.jpg\n",
      "facades/train/221.jpg\n",
      "facades/train/246.jpg\n",
      "facades/train/27.jpg\n",
      "facades/train/29.jpg\n",
      "facades/train/308.jpg\n",
      "facades/train/33.jpg\n",
      "facades/train/350.jpg\n",
      "facades/train/370.jpg\n",
      "facades/train/39.jpg\n",
      "facades/train/62.jpg\n",
      "facades/train/270.jpg\n",
      "facades/train/271.jpg\n",
      "facades/train/272.jpg\n",
      "facades/train/273.jpg\n",
      "facades/train/274.jpg\n",
      "facades/train/275.jpg\n",
      "facades/train/276.jpg\n",
      "facades/train/277.jpg\n",
      "facades/train/278.jpg\n",
      "facades/train/279.jpg\n",
      "facades/train/28.jpg\n",
      "facades/train/280.jpg\n",
      "facades/train/281.jpg\n",
      "facades/train/282.jpg\n",
      "facades/train/283.jpg\n",
      "facades/train/284.jpg\n",
      "facades/train/285.jpg\n",
      "facades/train/286.jpg\n",
      "facades/train/287.jpg\n",
      "facades/train/288.jpg\n",
      "facades/train/289.jpg\n",
      "facades/train/351.jpg\n",
      "facades/train/352.jpg\n",
      "facades/train/353.jpg\n",
      "facades/train/354.jpg\n",
      "facades/train/355.jpg\n",
      "facades/train/356.jpg\n",
      "facades/train/357.jpg\n",
      "facades/train/358.jpg\n",
      "facades/train/359.jpg\n",
      "facades/train/36.jpg\n",
      "facades/train/360.jpg\n",
      "facades/train/361.jpg\n",
      "facades/train/362.jpg\n",
      "facades/train/363.jpg\n",
      "facades/train/364.jpg\n",
      "facades/train/365.jpg\n",
      "facades/train/366.jpg\n",
      "facades/train/367.jpg\n",
      "facades/train/368.jpg\n",
      "facades/train/369.jpg\n",
      "facades/train/37.jpg\n",
      "facades/train/63.jpg\n",
      "facades/train/64.jpg\n",
      "facades/train/65.jpg\n",
      "facades/train/66.jpg\n",
      "facades/train/67.jpg\n",
      "facades/train/68.jpg\n",
      "facades/train/69.jpg\n",
      "facades/train/7.jpg\n",
      "facades/train/70.jpg\n",
      "facades/train/71.jpg\n",
      "facades/train/72.jpg\n",
      "facades/train/73.jpg\n",
      "facades/train/74.jpg\n",
      "facades/train/75.jpg\n",
      "facades/train/76.jpg\n",
      "facades/train/77.jpg\n",
      "facades/train/78.jpg\n",
      "facades/train/79.jpg\n",
      "facades/train/8.jpg\n",
      "facades/train/80.jpg\n",
      "facades/train/81.jpg\n",
      "facades/train/82.jpg\n",
      "facades/train/83.jpg\n",
      "facades/train/84.jpg\n",
      "facades/train/85.jpg\n",
      "facades/train/86.jpg\n",
      "facades/train/87.jpg\n",
      "facades/train/88.jpg\n",
      "facades/train/89.jpg\n",
      "facades/train/9.jpg\n",
      "facades/train/90.jpg\n",
      "facades/train/91.jpg\n",
      "facades/train/92.jpg\n",
      "facades/train/93.jpg\n",
      "facades/train/94.jpg\n",
      "facades/train/95.jpg\n",
      "facades/train/96.jpg\n",
      "facades/train/97.jpg\n",
      "facades/train/98.jpg\n",
      "facades/train/99.jpg\n",
      "facades/train/128.jpg\n",
      "facades/train/129.jpg\n",
      "facades/train/13.jpg\n",
      "facades/train/130.jpg\n",
      "facades/train/131.jpg\n",
      "facades/train/132.jpg\n",
      "facades/train/133.jpg\n",
      "facades/train/134.jpg\n",
      "facades/train/135.jpg\n",
      "facades/train/136.jpg\n",
      "facades/train/137.jpg\n",
      "facades/train/138.jpg\n",
      "facades/train/139.jpg\n",
      "facades/train/14.jpg\n",
      "facades/train/140.jpg\n",
      "facades/train/141.jpg\n",
      "facades/train/142.jpg\n",
      "facades/train/143.jpg\n",
      "facades/train/144.jpg\n",
      "facades/train/145.jpg\n",
      "facades/train/146.jpg\n",
      "facades/train/147.jpg\n",
      "facades/train/148.jpg\n",
      "facades/train/149.jpg\n",
      "facades/train/15.jpg\n",
      "facades/train/150.jpg\n",
      "facades/train/151.jpg\n",
      "facades/train/152.jpg\n",
      "facades/train/153.jpg\n",
      "facades/train/154.jpg\n",
      "facades/train/191.jpg\n",
      "facades/train/192.jpg\n",
      "facades/train/193.jpg\n",
      "facades/train/194.jpg\n",
      "facades/train/195.jpg\n",
      "facades/train/196.jpg\n",
      "facades/train/197.jpg\n",
      "facades/train/198.jpg\n",
      "facades/train/199.jpg\n",
      "facades/train/2.jpg\n",
      "facades/train/20.jpg\n",
      "facades/train/200.jpg\n",
      "facades/train/201.jpg\n",
      "facades/train/202.jpg\n",
      "facades/train/203.jpg\n",
      "facades/train/204.jpg\n",
      "facades/train/205.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facades/train/206.jpg\n",
      "facades/train/207.jpg\n",
      "facades/train/208.jpg\n",
      "facades/train/209.jpg\n",
      "facades/train/21.jpg\n",
      "facades/train/210.jpg\n",
      "facades/train/211.jpg\n",
      "facades/train/212.jpg\n",
      "facades/train/213.jpg\n",
      "facades/train/214.jpg\n",
      "facades/train/215.jpg\n",
      "facades/train/216.jpg\n",
      "facades/train/217.jpg\n",
      "facades/train/218.jpg\n",
      "facades/train/219.jpg\n",
      "facades/train/22.jpg\n",
      "facades/train/220.jpg\n",
      "facades/train/247.jpg\n",
      "facades/train/248.jpg\n",
      "facades/train/249.jpg\n",
      "facades/train/25.jpg\n",
      "facades/train/250.jpg\n",
      "facades/train/251.jpg\n",
      "facades/train/252.jpg\n",
      "facades/train/253.jpg\n",
      "facades/train/254.jpg\n",
      "facades/train/255.jpg\n",
      "facades/train/256.jpg\n",
      "facades/train/257.jpg\n",
      "facades/train/258.jpg\n",
      "facades/train/259.jpg\n",
      "facades/train/26.jpg\n",
      "facades/train/260.jpg\n",
      "facades/train/261.jpg\n",
      "facades/train/262.jpg\n",
      "facades/train/263.jpg\n",
      "facades/train/264.jpg\n",
      "facades/train/265.jpg\n",
      "facades/train/266.jpg\n",
      "facades/train/267.jpg\n",
      "facades/train/268.jpg\n",
      "facades/train/269.jpg\n",
      "facades/train/330.jpg\n",
      "facades/train/331.jpg\n",
      "facades/train/332.jpg\n",
      "facades/train/333.jpg\n",
      "facades/train/334.jpg\n",
      "facades/train/335.jpg\n",
      "facades/train/336.jpg\n",
      "facades/train/337.jpg\n",
      "facades/train/338.jpg\n",
      "facades/train/339.jpg\n",
      "facades/train/34.jpg\n",
      "facades/train/340.jpg\n",
      "facades/train/341.jpg\n",
      "facades/train/342.jpg\n",
      "facades/train/343.jpg\n",
      "facades/train/344.jpg\n",
      "facades/train/345.jpg\n",
      "facades/train/346.jpg\n",
      "facades/train/347.jpg\n",
      "facades/train/348.jpg\n",
      "facades/train/349.jpg\n",
      "facades/train/35.jpg\n",
      "facades/train/290.jpg\n",
      "facades/train/291.jpg\n",
      "facades/train/292.jpg\n",
      "facades/train/293.jpg\n",
      "facades/train/294.jpg\n",
      "facades/train/295.jpg\n",
      "facades/train/296.jpg\n",
      "facades/train/297.jpg\n",
      "facades/train/298.jpg\n",
      "facades/train/299.jpg\n",
      "facades/train/3.jpg\n",
      "facades/train/30.jpg\n",
      "facades/train/300.jpg\n",
      "facades/train/301.jpg\n",
      "facades/train/302.jpg\n",
      "facades/train/303.jpg\n",
      "facades/train/304.jpg\n",
      "facades/train/305.jpg\n",
      "facades/train/306.jpg\n",
      "facades/train/307.jpg\n",
      "facades/train/371.jpg\n",
      "facades/train/372.jpg\n",
      "facades/train/373.jpg\n",
      "facades/train/374.jpg\n",
      "facades/train/375.jpg\n",
      "facades/train/376.jpg\n",
      "facades/train/377.jpg\n",
      "facades/train/378.jpg\n",
      "facades/train/379.jpg\n",
      "facades/train/38.jpg\n",
      "facades/train/380.jpg\n",
      "facades/train/381.jpg\n",
      "facades/train/382.jpg\n",
      "facades/train/383.jpg\n",
      "facades/train/384.jpg\n",
      "facades/train/385.jpg\n",
      "facades/train/386.jpg\n",
      "facades/train/387.jpg\n",
      "facades/train/388.jpg\n",
      "facades/train/389.jpg\n",
      "facades/val/\n",
      "facades/val/30.jpg\n",
      "facades/val/50.jpg\n",
      "facades/val/73.jpg\n",
      "facades/val/1.jpg\n",
      "facades/val/10.jpg\n",
      "facades/val/100.jpg\n",
      "facades/val/11.jpg\n",
      "facades/val/12.jpg\n",
      "facades/val/13.jpg\n",
      "facades/val/14.jpg\n",
      "facades/val/15.jpg\n",
      "facades/val/16.jpg\n",
      "facades/val/17.jpg\n",
      "facades/val/18.jpg\n",
      "facades/val/19.jpg\n",
      "facades/val/2.jpg\n",
      "facades/val/20.jpg\n",
      "facades/val/21.jpg\n",
      "facades/val/22.jpg\n",
      "facades/val/23.jpg\n",
      "facades/val/24.jpg\n",
      "facades/val/25.jpg\n",
      "facades/val/26.jpg\n",
      "facades/val/27.jpg\n",
      "facades/val/28.jpg\n",
      "facades/val/29.jpg\n",
      "facades/val/3.jpg\n",
      "facades/val/51.jpg\n",
      "facades/val/52.jpg\n",
      "facades/val/53.jpg\n",
      "facades/val/54.jpg\n",
      "facades/val/55.jpg\n",
      "facades/val/56.jpg\n",
      "facades/val/57.jpg\n",
      "facades/val/58.jpg\n",
      "facades/val/59.jpg\n",
      "facades/val/6.jpg\n",
      "facades/val/60.jpg\n",
      "facades/val/61.jpg\n",
      "facades/val/62.jpg\n",
      "facades/val/63.jpg\n",
      "facades/val/64.jpg\n",
      "facades/val/65.jpg\n",
      "facades/val/66.jpg\n",
      "facades/val/67.jpg\n",
      "facades/val/68.jpg\n",
      "facades/val/69.jpg\n",
      "facades/val/7.jpg\n",
      "facades/val/70.jpg\n",
      "facades/val/71.jpg\n",
      "facades/val/72.jpg\n",
      "facades/val/74.jpg\n",
      "facades/val/75.jpg\n",
      "facades/val/76.jpg\n",
      "facades/val/77.jpg\n",
      "facades/val/78.jpg\n",
      "facades/val/79.jpg\n",
      "facades/val/8.jpg\n",
      "facades/val/80.jpg\n",
      "facades/val/81.jpg\n",
      "facades/val/82.jpg\n",
      "facades/val/83.jpg\n",
      "facades/val/84.jpg\n",
      "facades/val/85.jpg\n",
      "facades/val/86.jpg\n",
      "facades/val/87.jpg\n",
      "facades/val/88.jpg\n",
      "facades/val/89.jpg\n",
      "facades/val/9.jpg\n",
      "facades/val/90.jpg\n",
      "facades/val/91.jpg\n",
      "facades/val/92.jpg\n",
      "facades/val/93.jpg\n",
      "facades/val/94.jpg\n",
      "facades/val/95.jpg\n",
      "facades/val/96.jpg\n",
      "facades/val/97.jpg\n",
      "facades/val/98.jpg\n",
      "facades/val/99.jpg\n",
      "facades/val/31.jpg\n",
      "facades/val/32.jpg\n",
      "facades/val/33.jpg\n",
      "facades/val/34.jpg\n",
      "facades/val/35.jpg\n",
      "facades/val/36.jpg\n",
      "facades/val/37.jpg\n",
      "facades/val/38.jpg\n",
      "facades/val/39.jpg\n",
      "facades/val/4.jpg\n",
      "facades/val/40.jpg\n",
      "facades/val/41.jpg\n",
      "facades/val/42.jpg\n",
      "facades/val/43.jpg\n",
      "facades/val/44.jpg\n",
      "facades/val/45.jpg\n",
      "facades/val/46.jpg\n",
      "facades/val/47.jpg\n",
      "facades/val/48.jpg\n",
      "facades/val/49.jpg\n",
      "facades/val/5.jpg\n"
     ]
    }
   ],
   "source": [
    "!bash ./datasets/download_pix2pix_dataset.sh facades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GC2DEP4M0OsS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
      "Specified [facades_label2photo]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2024-12-01 12:20:08--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/facades_label2photo.pth\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 217704720 (208M)\n",
      "Saving to: ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/facad 100%[===================>] 207.62M  66.3MB/s    in 3.1s    \n",
      "\n",
      "2024-12-01 12:20:11 (66.3 MB/s) - ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’ saved [217704720/217704720]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/download_pix2pix_model.sh facades_label2photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/facades            \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: facades_pix2pix               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 400\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/facades_pix2pix/web...\n",
      "/opt/conda/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.103, data: 1.205) G_GAN: 1.724 G_L1: 43.477 D_real: 0.187 D_fake: 0.512 \n",
      "(epoch: 1, iters: 200, time: 0.108, data: 0.002) G_GAN: 1.545 G_L1: 37.026 D_real: 0.134 D_fake: 0.254 \n",
      "(epoch: 1, iters: 300, time: 0.106, data: 0.002) G_GAN: 2.938 G_L1: 36.490 D_real: 0.024 D_fake: 0.140 \n",
      "(epoch: 1, iters: 400, time: 0.360, data: 0.002) G_GAN: 2.565 G_L1: 33.536 D_real: 0.603 D_fake: 0.039 \n",
      "End of epoch 1 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 100, time: 0.106, data: 0.265) G_GAN: 2.949 G_L1: 33.456 D_real: 0.077 D_fake: 0.577 \n",
      "(epoch: 2, iters: 200, time: 0.110, data: 0.002) G_GAN: 1.408 G_L1: 24.876 D_real: 0.751 D_fake: 0.473 \n",
      "(epoch: 2, iters: 300, time: 0.108, data: 0.002) G_GAN: 3.002 G_L1: 31.336 D_real: 0.009 D_fake: 0.831 \n",
      "(epoch: 2, iters: 400, time: 0.242, data: 0.002) G_GAN: 2.260 G_L1: 26.613 D_real: 0.766 D_fake: 0.044 \n",
      "End of epoch 2 / 200 \t Time Taken: 26 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 100, time: 0.110, data: 0.271) G_GAN: 2.083 G_L1: 32.068 D_real: 0.049 D_fake: 0.358 \n",
      "(epoch: 3, iters: 200, time: 0.103, data: 0.002) G_GAN: 3.104 G_L1: 31.182 D_real: 0.024 D_fake: 0.115 \n",
      "(epoch: 3, iters: 300, time: 0.110, data: 0.002) G_GAN: 3.152 G_L1: 27.903 D_real: 0.538 D_fake: 0.083 \n",
      "(epoch: 3, iters: 400, time: 0.230, data: 0.002) G_GAN: 2.169 G_L1: 30.598 D_real: 0.128 D_fake: 0.328 \n",
      "End of epoch 3 / 200 \t Time Taken: 26 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 100, time: 0.111, data: 0.267) G_GAN: 0.575 G_L1: 37.281 D_real: 1.496 D_fake: 0.037 \n",
      "(epoch: 4, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.130 G_L1: 54.683 D_real: 0.010 D_fake: 0.062 \n",
      "(epoch: 4, iters: 300, time: 0.110, data: 0.002) G_GAN: 1.370 G_L1: 37.759 D_real: 1.812 D_fake: 0.021 \n",
      "(epoch: 4, iters: 400, time: 0.217, data: 0.002) G_GAN: 2.898 G_L1: 29.488 D_real: 0.097 D_fake: 0.601 \n",
      "End of epoch 4 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 100, time: 0.112, data: 0.286) G_GAN: 4.798 G_L1: 36.172 D_real: 0.002 D_fake: 1.013 \n",
      "(epoch: 5, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.264 G_L1: 32.440 D_real: 0.057 D_fake: 0.074 \n",
      "(epoch: 5, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.166 G_L1: 36.905 D_real: 0.076 D_fake: 0.117 \n",
      "(epoch: 5, iters: 400, time: 0.249, data: 0.002) G_GAN: 3.264 G_L1: 32.594 D_real: 0.017 D_fake: 0.373 \n",
      "saving the model at the end of epoch 5, iters 2000\n",
      "End of epoch 5 / 200 \t Time Taken: 29 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.113, data: 0.294) G_GAN: 2.504 G_L1: 33.286 D_real: 0.135 D_fake: 0.166 \n",
      "(epoch: 6, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.286 G_L1: 29.767 D_real: 0.009 D_fake: 0.145 \n",
      "(epoch: 6, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.622 G_L1: 36.971 D_real: 0.078 D_fake: 0.017 \n",
      "(epoch: 6, iters: 400, time: 0.246, data: 0.002) G_GAN: 3.424 G_L1: 34.396 D_real: 0.005 D_fake: 1.171 \n",
      "End of epoch 6 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 100, time: 0.112, data: 0.296) G_GAN: 3.043 G_L1: 41.808 D_real: 0.043 D_fake: 0.269 \n",
      "(epoch: 7, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.117 G_L1: 31.142 D_real: 0.051 D_fake: 0.066 \n",
      "(epoch: 7, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.994 G_L1: 39.366 D_real: 0.011 D_fake: 0.072 \n",
      "(epoch: 7, iters: 400, time: 0.232, data: 0.002) G_GAN: 2.231 G_L1: 33.698 D_real: 0.365 D_fake: 0.092 \n",
      "End of epoch 7 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 100, time: 0.112, data: 0.283) G_GAN: 2.579 G_L1: 30.596 D_real: 0.158 D_fake: 0.392 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 8, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.395 G_L1: 30.949 D_real: 0.062 D_fake: 0.058 \n",
      "(epoch: 8, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.772 G_L1: 29.329 D_real: 0.919 D_fake: 0.048 \n",
      "(epoch: 8, iters: 400, time: 0.257, data: 0.002) G_GAN: 2.276 G_L1: 33.296 D_real: 0.005 D_fake: 1.035 \n",
      "End of epoch 8 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 100, time: 0.111, data: 0.265) G_GAN: 2.885 G_L1: 44.151 D_real: 0.014 D_fake: 0.470 \n",
      "(epoch: 9, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.025 G_L1: 49.294 D_real: 0.002 D_fake: 0.103 \n",
      "(epoch: 9, iters: 300, time: 0.115, data: 0.002) G_GAN: 3.072 G_L1: 38.893 D_real: 0.022 D_fake: 0.105 \n",
      "(epoch: 9, iters: 400, time: 0.245, data: 0.002) G_GAN: 1.820 G_L1: 31.510 D_real: 0.008 D_fake: 0.181 \n",
      "End of epoch 9 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 100, time: 0.113, data: 0.274) G_GAN: 3.006 G_L1: 30.272 D_real: 0.550 D_fake: 0.041 \n",
      "(epoch: 10, iters: 200, time: 0.112, data: 0.002) G_GAN: 1.594 G_L1: 27.814 D_real: 0.701 D_fake: 0.412 \n",
      "(epoch: 10, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.255 G_L1: 38.999 D_real: 0.020 D_fake: 0.527 \n",
      "(epoch: 10, iters: 400, time: 0.251, data: 0.002) G_GAN: 1.421 G_L1: 28.500 D_real: 1.127 D_fake: 0.122 \n",
      "saving the model at the end of epoch 10, iters 4000\n",
      "End of epoch 10 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.111, data: 0.333) G_GAN: 2.090 G_L1: 28.715 D_real: 0.214 D_fake: 1.516 \n",
      "(epoch: 11, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.879 G_L1: 35.050 D_real: 0.177 D_fake: 0.042 \n",
      "(epoch: 11, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.403 G_L1: 38.194 D_real: 0.063 D_fake: 0.232 \n",
      "(epoch: 11, iters: 400, time: 0.252, data: 0.002) G_GAN: 3.250 G_L1: 32.942 D_real: 0.012 D_fake: 0.099 \n",
      "End of epoch 11 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 100, time: 0.112, data: 0.280) G_GAN: 2.914 G_L1: 37.394 D_real: 0.095 D_fake: 0.119 \n",
      "(epoch: 12, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.342 G_L1: 33.132 D_real: 0.229 D_fake: 0.038 \n",
      "(epoch: 12, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.520 G_L1: 30.842 D_real: 0.015 D_fake: 0.370 \n",
      "(epoch: 12, iters: 400, time: 0.258, data: 0.002) G_GAN: 2.365 G_L1: 34.413 D_real: 0.303 D_fake: 0.088 \n",
      "End of epoch 12 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 100, time: 0.113, data: 0.273) G_GAN: 1.015 G_L1: 24.673 D_real: 1.440 D_fake: 0.204 \n",
      "(epoch: 13, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.334 G_L1: 38.790 D_real: 0.408 D_fake: 0.057 \n",
      "saving the latest model (epoch 13, total_iters 5000)\n",
      "(epoch: 13, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.494 G_L1: 45.836 D_real: 0.011 D_fake: 0.034 \n",
      "(epoch: 13, iters: 400, time: 0.262, data: 0.002) G_GAN: 1.480 G_L1: 23.727 D_real: 0.494 D_fake: 0.056 \n",
      "End of epoch 13 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 100, time: 0.111, data: 0.272) G_GAN: 0.785 G_L1: 25.778 D_real: 1.839 D_fake: 0.352 \n",
      "(epoch: 14, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.552 G_L1: 27.770 D_real: 0.077 D_fake: 0.441 \n",
      "(epoch: 14, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.144 G_L1: 29.636 D_real: 0.225 D_fake: 0.181 \n",
      "(epoch: 14, iters: 400, time: 0.259, data: 0.002) G_GAN: 1.784 G_L1: 31.947 D_real: 0.311 D_fake: 0.108 \n",
      "End of epoch 14 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 100, time: 0.112, data: 0.291) G_GAN: 1.621 G_L1: 40.306 D_real: 0.007 D_fake: 0.228 \n",
      "(epoch: 15, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.149 G_L1: 29.760 D_real: 0.987 D_fake: 0.022 \n",
      "(epoch: 15, iters: 300, time: 0.112, data: 0.003) G_GAN: 3.370 G_L1: 36.902 D_real: 0.068 D_fake: 0.054 \n",
      "(epoch: 15, iters: 400, time: 0.264, data: 0.002) G_GAN: 4.070 G_L1: 38.328 D_real: 0.032 D_fake: 0.025 \n",
      "saving the model at the end of epoch 15, iters 6000\n",
      "End of epoch 15 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.112, data: 0.300) G_GAN: 2.223 G_L1: 38.859 D_real: 0.001 D_fake: 0.639 \n",
      "(epoch: 16, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.147 G_L1: 24.732 D_real: 0.357 D_fake: 0.273 \n",
      "(epoch: 16, iters: 300, time: 0.112, data: 0.002) G_GAN: 1.543 G_L1: 26.881 D_real: 2.491 D_fake: 0.080 \n",
      "(epoch: 16, iters: 400, time: 0.265, data: 0.002) G_GAN: 1.549 G_L1: 31.239 D_real: 0.389 D_fake: 0.811 \n",
      "End of epoch 16 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 17, iters: 100, time: 0.113, data: 0.320) G_GAN: 2.151 G_L1: 29.279 D_real: 1.308 D_fake: 0.109 \n",
      "(epoch: 17, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.825 G_L1: 35.220 D_real: 0.031 D_fake: 0.588 \n",
      "(epoch: 17, iters: 300, time: 0.112, data: 0.002) G_GAN: 1.055 G_L1: 22.339 D_real: 0.588 D_fake: 0.386 \n",
      "(epoch: 17, iters: 400, time: 0.271, data: 0.002) G_GAN: 3.651 G_L1: 34.894 D_real: 0.064 D_fake: 0.046 \n",
      "End of epoch 17 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 100, time: 0.107, data: 0.292) G_GAN: 1.644 G_L1: 26.039 D_real: 0.106 D_fake: 0.263 \n",
      "(epoch: 18, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.223 G_L1: 30.377 D_real: 0.029 D_fake: 0.348 \n",
      "(epoch: 18, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.527 G_L1: 39.020 D_real: 0.011 D_fake: 0.119 \n",
      "(epoch: 18, iters: 400, time: 0.265, data: 0.002) G_GAN: 1.681 G_L1: 28.029 D_real: 0.129 D_fake: 0.298 \n",
      "End of epoch 18 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 19, iters: 100, time: 0.111, data: 0.292) G_GAN: 2.288 G_L1: 40.583 D_real: 0.011 D_fake: 0.295 \n",
      "(epoch: 19, iters: 200, time: 0.113, data: 0.002) G_GAN: 1.742 G_L1: 25.615 D_real: 0.257 D_fake: 0.213 \n",
      "(epoch: 19, iters: 300, time: 0.113, data: 0.002) G_GAN: 0.627 G_L1: 29.670 D_real: 1.401 D_fake: 0.117 \n",
      "(epoch: 19, iters: 400, time: 0.246, data: 0.002) G_GAN: 1.315 G_L1: 28.588 D_real: 0.494 D_fake: 0.429 \n",
      "End of epoch 19 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 100, time: 0.113, data: 0.268) G_GAN: 1.326 G_L1: 30.124 D_real: 0.615 D_fake: 0.301 \n",
      "(epoch: 20, iters: 200, time: 0.110, data: 0.002) G_GAN: 2.710 G_L1: 35.818 D_real: 0.649 D_fake: 0.036 \n",
      "(epoch: 20, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.825 G_L1: 31.984 D_real: 0.114 D_fake: 0.051 \n",
      "(epoch: 20, iters: 400, time: 0.258, data: 0.002) G_GAN: 3.230 G_L1: 27.010 D_real: 0.127 D_fake: 0.555 \n",
      "saving the model at the end of epoch 20, iters 8000\n",
      "End of epoch 20 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.109, data: 0.302) G_GAN: 2.559 G_L1: 41.502 D_real: 0.142 D_fake: 0.166 \n",
      "(epoch: 21, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.020 G_L1: 21.309 D_real: 3.412 D_fake: 0.014 \n",
      "(epoch: 21, iters: 300, time: 0.112, data: 0.002) G_GAN: 1.403 G_L1: 21.223 D_real: 2.386 D_fake: 0.091 \n",
      "(epoch: 21, iters: 400, time: 0.270, data: 0.002) G_GAN: 0.923 G_L1: 27.899 D_real: 2.397 D_fake: 0.081 \n",
      "End of epoch 21 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 100, time: 0.113, data: 0.278) G_GAN: 3.234 G_L1: 45.344 D_real: 0.039 D_fake: 0.082 \n",
      "(epoch: 22, iters: 200, time: 0.113, data: 0.002) G_GAN: 1.292 G_L1: 24.290 D_real: 2.268 D_fake: 0.059 \n",
      "(epoch: 22, iters: 300, time: 0.106, data: 0.002) G_GAN: 3.379 G_L1: 29.373 D_real: 0.449 D_fake: 0.030 \n",
      "(epoch: 22, iters: 400, time: 0.269, data: 0.002) G_GAN: 2.275 G_L1: 25.054 D_real: 0.105 D_fake: 0.182 \n",
      "End of epoch 22 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 100, time: 0.112, data: 0.274) G_GAN: 2.721 G_L1: 33.754 D_real: 0.064 D_fake: 0.103 \n",
      "(epoch: 23, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.024 G_L1: 31.332 D_real: 0.020 D_fake: 0.194 \n",
      "(epoch: 23, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.177 G_L1: 28.372 D_real: 0.074 D_fake: 0.823 \n",
      "(epoch: 23, iters: 400, time: 0.282, data: 0.002) G_GAN: 4.200 G_L1: 32.597 D_real: 0.385 D_fake: 0.018 \n",
      "End of epoch 23 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 24, iters: 100, time: 0.112, data: 0.297) G_GAN: 2.572 G_L1: 37.651 D_real: 0.140 D_fake: 0.102 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 24, iters: 200, time: 0.111, data: 0.002) G_GAN: 1.240 G_L1: 29.112 D_real: 0.535 D_fake: 0.578 \n",
      "(epoch: 24, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.886 G_L1: 26.895 D_real: 0.002 D_fake: 1.166 \n",
      "(epoch: 24, iters: 400, time: 0.273, data: 0.002) G_GAN: 2.827 G_L1: 31.144 D_real: 0.010 D_fake: 0.144 \n",
      "End of epoch 24 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 100, time: 0.114, data: 0.285) G_GAN: 2.460 G_L1: 28.809 D_real: 0.017 D_fake: 0.243 \n",
      "(epoch: 25, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.671 G_L1: 29.678 D_real: 0.181 D_fake: 0.108 \n",
      "(epoch: 25, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.991 G_L1: 35.659 D_real: 0.004 D_fake: 1.075 \n",
      "(epoch: 25, iters: 400, time: 0.267, data: 0.002) G_GAN: 1.997 G_L1: 47.343 D_real: 0.054 D_fake: 0.292 \n",
      "saving the latest model (epoch 25, total_iters 10000)\n",
      "saving the model at the end of epoch 25, iters 10000\n",
      "End of epoch 25 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.111, data: 0.298) G_GAN: 3.045 G_L1: 35.417 D_real: 0.023 D_fake: 0.232 \n",
      "(epoch: 26, iters: 200, time: 0.112, data: 0.002) G_GAN: 1.934 G_L1: 32.017 D_real: 0.027 D_fake: 0.470 \n",
      "(epoch: 26, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.158 G_L1: 32.020 D_real: 0.383 D_fake: 0.168 \n",
      "(epoch: 26, iters: 400, time: 0.282, data: 0.002) G_GAN: 3.162 G_L1: 27.622 D_real: 0.500 D_fake: 0.026 \n",
      "End of epoch 26 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 27, iters: 100, time: 0.115, data: 0.314) G_GAN: 1.896 G_L1: 28.075 D_real: 0.026 D_fake: 0.390 \n",
      "(epoch: 27, iters: 200, time: 0.112, data: 0.002) G_GAN: 0.306 G_L1: 26.583 D_real: 2.947 D_fake: 0.741 \n",
      "(epoch: 27, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.549 G_L1: 30.874 D_real: 0.271 D_fake: 0.409 \n",
      "(epoch: 27, iters: 400, time: 0.272, data: 0.002) G_GAN: 3.249 G_L1: 43.344 D_real: 0.015 D_fake: 0.114 \n",
      "End of epoch 27 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 100, time: 0.111, data: 0.296) G_GAN: 1.738 G_L1: 30.517 D_real: 0.592 D_fake: 0.103 \n",
      "(epoch: 28, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.048 G_L1: 37.645 D_real: 0.003 D_fake: 1.333 \n",
      "(epoch: 28, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.601 G_L1: 27.346 D_real: 0.096 D_fake: 0.038 \n",
      "(epoch: 28, iters: 400, time: 0.367, data: 0.002) G_GAN: 2.140 G_L1: 27.640 D_real: 0.229 D_fake: 0.321 \n",
      "End of epoch 28 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 100, time: 0.112, data: 0.292) G_GAN: 1.883 G_L1: 23.821 D_real: 0.620 D_fake: 0.197 \n",
      "(epoch: 29, iters: 200, time: 0.108, data: 0.002) G_GAN: 3.582 G_L1: 37.000 D_real: 0.165 D_fake: 0.050 \n",
      "(epoch: 29, iters: 300, time: 0.110, data: 0.002) G_GAN: 1.818 G_L1: 24.141 D_real: 0.789 D_fake: 0.032 \n",
      "(epoch: 29, iters: 400, time: 0.293, data: 0.002) G_GAN: 2.089 G_L1: 37.915 D_real: 0.002 D_fake: 0.702 \n",
      "End of epoch 29 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 100, time: 0.111, data: 0.316) G_GAN: 3.048 G_L1: 30.366 D_real: 0.146 D_fake: 0.064 \n",
      "(epoch: 30, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.279 G_L1: 27.173 D_real: 0.016 D_fake: 0.590 \n",
      "(epoch: 30, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.442 G_L1: 43.390 D_real: 0.000 D_fake: 1.015 \n",
      "(epoch: 30, iters: 400, time: 0.298, data: 0.002) G_GAN: 2.081 G_L1: 24.488 D_real: 0.329 D_fake: 0.206 \n",
      "saving the model at the end of epoch 30, iters 12000\n",
      "End of epoch 30 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.113, data: 0.311) G_GAN: 3.894 G_L1: 32.334 D_real: 0.126 D_fake: 0.029 \n",
      "(epoch: 31, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.680 G_L1: 35.260 D_real: 0.001 D_fake: 0.053 \n",
      "(epoch: 31, iters: 300, time: 0.109, data: 0.002) G_GAN: 1.512 G_L1: 28.185 D_real: 0.437 D_fake: 0.142 \n",
      "(epoch: 31, iters: 400, time: 0.281, data: 0.002) G_GAN: 1.694 G_L1: 36.280 D_real: 0.024 D_fake: 0.176 \n",
      "End of epoch 31 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 32, iters: 100, time: 0.108, data: 0.283) G_GAN: 2.950 G_L1: 29.971 D_real: 0.546 D_fake: 0.031 \n",
      "(epoch: 32, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.902 G_L1: 34.972 D_real: 0.005 D_fake: 0.056 \n",
      "(epoch: 32, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.844 G_L1: 33.937 D_real: 0.403 D_fake: 0.355 \n",
      "(epoch: 32, iters: 400, time: 0.284, data: 0.002) G_GAN: 2.986 G_L1: 41.143 D_real: 0.034 D_fake: 0.094 \n",
      "End of epoch 32 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 100, time: 0.110, data: 0.302) G_GAN: 2.254 G_L1: 28.726 D_real: 0.137 D_fake: 0.251 \n",
      "(epoch: 33, iters: 200, time: 0.099, data: 0.002) G_GAN: 3.129 G_L1: 25.558 D_real: 0.242 D_fake: 0.065 \n",
      "(epoch: 33, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.273 G_L1: 30.525 D_real: 0.052 D_fake: 0.122 \n",
      "(epoch: 33, iters: 400, time: 0.296, data: 0.002) G_GAN: 2.980 G_L1: 34.562 D_real: 0.268 D_fake: 0.047 \n",
      "End of epoch 33 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 34, iters: 100, time: 0.110, data: 0.307) G_GAN: 1.772 G_L1: 39.064 D_real: 0.811 D_fake: 0.129 \n",
      "(epoch: 34, iters: 200, time: 0.111, data: 0.003) G_GAN: 2.891 G_L1: 36.294 D_real: 0.043 D_fake: 0.264 \n",
      "(epoch: 34, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.065 G_L1: 22.893 D_real: 0.256 D_fake: 0.157 \n",
      "(epoch: 34, iters: 400, time: 0.296, data: 0.002) G_GAN: 1.913 G_L1: 30.638 D_real: 1.976 D_fake: 0.075 \n",
      "End of epoch 34 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 100, time: 0.112, data: 0.302) G_GAN: 2.832 G_L1: 31.271 D_real: 0.082 D_fake: 0.297 \n",
      "(epoch: 35, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.062 G_L1: 44.872 D_real: 0.376 D_fake: 0.110 \n",
      "(epoch: 35, iters: 300, time: 0.112, data: 0.002) G_GAN: 0.621 G_L1: 28.452 D_real: 1.717 D_fake: 0.272 \n",
      "(epoch: 35, iters: 400, time: 0.291, data: 0.002) G_GAN: 2.587 G_L1: 47.760 D_real: 0.003 D_fake: 0.283 \n",
      "saving the model at the end of epoch 35, iters 14000\n",
      "End of epoch 35 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.112, data: 0.333) G_GAN: 2.392 G_L1: 31.240 D_real: 0.011 D_fake: 0.191 \n",
      "(epoch: 36, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.449 G_L1: 25.250 D_real: 0.317 D_fake: 0.313 \n",
      "(epoch: 36, iters: 300, time: 0.111, data: 0.002) G_GAN: 0.801 G_L1: 30.672 D_real: 1.461 D_fake: 0.279 \n",
      "(epoch: 36, iters: 400, time: 0.306, data: 0.002) G_GAN: 2.843 G_L1: 29.526 D_real: 0.195 D_fake: 0.061 \n",
      "End of epoch 36 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 37, iters: 100, time: 0.114, data: 0.288) G_GAN: 2.109 G_L1: 31.252 D_real: 0.249 D_fake: 0.128 \n",
      "(epoch: 37, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.035 G_L1: 32.578 D_real: 0.203 D_fake: 0.295 \n",
      "(epoch: 37, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.576 G_L1: 44.018 D_real: 0.000 D_fake: 0.245 \n",
      "(epoch: 37, iters: 400, time: 0.289, data: 0.002) G_GAN: 1.624 G_L1: 33.713 D_real: 0.003 D_fake: 1.378 \n",
      "End of epoch 37 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 100, time: 0.111, data: 0.284) G_GAN: 2.295 G_L1: 30.287 D_real: 0.007 D_fake: 0.312 \n",
      "(epoch: 38, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.378 G_L1: 39.060 D_real: 0.113 D_fake: 0.159 \n",
      "saving the latest model (epoch 38, total_iters 15000)\n",
      "(epoch: 38, iters: 300, time: 0.110, data: 0.002) G_GAN: 2.807 G_L1: 24.391 D_real: 0.103 D_fake: 0.368 \n",
      "(epoch: 38, iters: 400, time: 0.293, data: 0.002) G_GAN: 2.693 G_L1: 29.384 D_real: 0.017 D_fake: 0.191 \n",
      "End of epoch 38 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 39, iters: 100, time: 0.112, data: 0.294) G_GAN: 3.890 G_L1: 29.312 D_real: 0.029 D_fake: 0.037 \n",
      "(epoch: 39, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.783 G_L1: 40.720 D_real: 0.080 D_fake: 0.094 \n",
      "(epoch: 39, iters: 300, time: 0.115, data: 0.002) G_GAN: 2.840 G_L1: 27.177 D_real: 0.109 D_fake: 0.542 \n",
      "(epoch: 39, iters: 400, time: 0.293, data: 0.002) G_GAN: 1.909 G_L1: 28.579 D_real: 0.654 D_fake: 0.097 \n",
      "End of epoch 39 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 100, time: 0.112, data: 0.279) G_GAN: 2.306 G_L1: 25.071 D_real: 0.166 D_fake: 0.071 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 40, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.774 G_L1: 25.545 D_real: 0.443 D_fake: 0.043 \n",
      "(epoch: 40, iters: 300, time: 0.114, data: 0.002) G_GAN: 1.623 G_L1: 25.774 D_real: 0.281 D_fake: 0.602 \n",
      "(epoch: 40, iters: 400, time: 0.323, data: 0.002) G_GAN: 1.750 G_L1: 20.436 D_real: 0.365 D_fake: 0.526 \n",
      "saving the model at the end of epoch 40, iters 16000\n",
      "End of epoch 40 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.111, data: 0.308) G_GAN: 2.534 G_L1: 28.808 D_real: 0.152 D_fake: 0.258 \n",
      "(epoch: 41, iters: 200, time: 0.112, data: 0.002) G_GAN: 0.915 G_L1: 23.999 D_real: 1.727 D_fake: 0.119 \n",
      "(epoch: 41, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.769 G_L1: 27.458 D_real: 0.016 D_fake: 0.474 \n",
      "(epoch: 41, iters: 400, time: 0.349, data: 0.002) G_GAN: 2.170 G_L1: 32.798 D_real: 0.418 D_fake: 0.071 \n",
      "End of epoch 41 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 42, iters: 100, time: 0.113, data: 0.276) G_GAN: 1.751 G_L1: 33.078 D_real: 0.131 D_fake: 0.190 \n",
      "(epoch: 42, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.475 G_L1: 33.942 D_real: 0.063 D_fake: 0.092 \n",
      "(epoch: 42, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.104 G_L1: 31.258 D_real: 0.034 D_fake: 0.429 \n",
      "(epoch: 42, iters: 400, time: 0.314, data: 0.002) G_GAN: 1.725 G_L1: 23.491 D_real: 0.786 D_fake: 0.179 \n",
      "End of epoch 42 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 100, time: 0.113, data: 0.304) G_GAN: 2.686 G_L1: 28.256 D_real: 0.015 D_fake: 0.283 \n",
      "(epoch: 43, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.438 G_L1: 34.906 D_real: 0.202 D_fake: 0.042 \n",
      "(epoch: 43, iters: 300, time: 0.110, data: 0.002) G_GAN: 1.559 G_L1: 25.533 D_real: 0.738 D_fake: 0.665 \n",
      "(epoch: 43, iters: 400, time: 0.291, data: 0.002) G_GAN: 2.167 G_L1: 49.641 D_real: 0.000 D_fake: 0.858 \n",
      "End of epoch 43 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 44, iters: 100, time: 0.113, data: 0.288) G_GAN: 1.611 G_L1: 30.023 D_real: 0.223 D_fake: 0.294 \n",
      "(epoch: 44, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.062 G_L1: 31.919 D_real: 0.065 D_fake: 0.126 \n",
      "(epoch: 44, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.044 G_L1: 39.652 D_real: 0.000 D_fake: 0.248 \n",
      "(epoch: 44, iters: 400, time: 0.310, data: 0.002) G_GAN: 2.800 G_L1: 38.974 D_real: 0.004 D_fake: 0.247 \n",
      "End of epoch 44 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 100, time: 0.113, data: 0.281) G_GAN: 1.194 G_L1: 26.972 D_real: 1.141 D_fake: 0.069 \n",
      "(epoch: 45, iters: 200, time: 0.114, data: 0.002) G_GAN: 2.716 G_L1: 26.060 D_real: 0.680 D_fake: 0.039 \n",
      "(epoch: 45, iters: 300, time: 0.111, data: 0.002) G_GAN: 3.515 G_L1: 33.319 D_real: 0.051 D_fake: 0.122 \n",
      "(epoch: 45, iters: 400, time: 0.318, data: 0.002) G_GAN: 3.104 G_L1: 29.821 D_real: 0.036 D_fake: 0.119 \n",
      "saving the model at the end of epoch 45, iters 18000\n",
      "End of epoch 45 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.112, data: 0.285) G_GAN: 3.149 G_L1: 31.446 D_real: 0.146 D_fake: 0.083 \n",
      "(epoch: 46, iters: 200, time: 0.113, data: 0.002) G_GAN: 1.870 G_L1: 26.534 D_real: 0.381 D_fake: 0.164 \n",
      "(epoch: 46, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.574 G_L1: 33.677 D_real: 0.005 D_fake: 0.182 \n",
      "(epoch: 46, iters: 400, time: 0.325, data: 0.002) G_GAN: 1.565 G_L1: 21.438 D_real: 0.828 D_fake: 0.092 \n",
      "End of epoch 46 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 100, time: 0.108, data: 0.294) G_GAN: 0.808 G_L1: 21.065 D_real: 1.744 D_fake: 0.130 \n",
      "(epoch: 47, iters: 200, time: 0.100, data: 0.002) G_GAN: 2.210 G_L1: 24.666 D_real: 2.190 D_fake: 0.016 \n",
      "(epoch: 47, iters: 300, time: 0.114, data: 0.002) G_GAN: 1.209 G_L1: 21.511 D_real: 0.662 D_fake: 0.205 \n",
      "(epoch: 47, iters: 400, time: 0.413, data: 0.002) G_GAN: 1.348 G_L1: 20.751 D_real: 0.768 D_fake: 0.317 \n",
      "End of epoch 47 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 100, time: 0.111, data: 0.269) G_GAN: 2.817 G_L1: 26.953 D_real: 0.017 D_fake: 0.709 \n",
      "(epoch: 48, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.642 G_L1: 30.122 D_real: 0.072 D_fake: 0.078 \n",
      "(epoch: 48, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.030 G_L1: 29.506 D_real: 0.052 D_fake: 0.316 \n",
      "(epoch: 48, iters: 400, time: 0.301, data: 0.002) G_GAN: 2.210 G_L1: 27.186 D_real: 0.899 D_fake: 0.038 \n",
      "End of epoch 48 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 49, iters: 100, time: 0.111, data: 0.329) G_GAN: 2.812 G_L1: 26.511 D_real: 0.125 D_fake: 0.280 \n",
      "(epoch: 49, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.000 G_L1: 27.004 D_real: 0.076 D_fake: 0.143 \n",
      "(epoch: 49, iters: 300, time: 0.114, data: 0.002) G_GAN: 3.499 G_L1: 35.831 D_real: 0.006 D_fake: 0.052 \n",
      "(epoch: 49, iters: 400, time: 0.335, data: 0.002) G_GAN: 2.582 G_L1: 34.885 D_real: 0.187 D_fake: 0.179 \n",
      "End of epoch 49 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 100, time: 0.111, data: 0.297) G_GAN: 3.217 G_L1: 32.444 D_real: 0.123 D_fake: 0.157 \n",
      "(epoch: 50, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.837 G_L1: 28.289 D_real: 0.244 D_fake: 0.035 \n",
      "(epoch: 50, iters: 300, time: 0.112, data: 0.002) G_GAN: 5.469 G_L1: 32.629 D_real: 0.022 D_fake: 0.011 \n",
      "(epoch: 50, iters: 400, time: 0.321, data: 0.002) G_GAN: 1.937 G_L1: 28.948 D_real: 0.183 D_fake: 0.354 \n",
      "saving the latest model (epoch 50, total_iters 20000)\n",
      "saving the model at the end of epoch 50, iters 20000\n",
      "End of epoch 50 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.112, data: 0.292) G_GAN: 3.248 G_L1: 29.086 D_real: 0.670 D_fake: 0.018 \n",
      "(epoch: 51, iters: 200, time: 0.113, data: 0.002) G_GAN: 1.199 G_L1: 19.072 D_real: 0.768 D_fake: 0.340 \n",
      "(epoch: 51, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.167 G_L1: 29.591 D_real: 0.741 D_fake: 0.202 \n",
      "(epoch: 51, iters: 400, time: 0.330, data: 0.002) G_GAN: 3.503 G_L1: 39.225 D_real: 0.002 D_fake: 0.100 \n",
      "End of epoch 51 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 52, iters: 100, time: 0.113, data: 0.303) G_GAN: 2.719 G_L1: 32.051 D_real: 0.003 D_fake: 0.112 \n",
      "(epoch: 52, iters: 200, time: 0.113, data: 0.002) G_GAN: 1.336 G_L1: 28.978 D_real: 0.877 D_fake: 0.148 \n",
      "(epoch: 52, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.572 G_L1: 21.827 D_real: 0.091 D_fake: 0.671 \n",
      "(epoch: 52, iters: 400, time: 0.346, data: 0.002) G_GAN: 2.941 G_L1: 31.989 D_real: 0.007 D_fake: 0.327 \n",
      "End of epoch 52 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 53, iters: 100, time: 0.109, data: 0.291) G_GAN: 2.637 G_L1: 32.837 D_real: 0.007 D_fake: 0.186 \n",
      "(epoch: 53, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.758 G_L1: 25.826 D_real: 0.204 D_fake: 0.080 \n",
      "(epoch: 53, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.379 G_L1: 34.994 D_real: 0.004 D_fake: 0.048 \n",
      "(epoch: 53, iters: 400, time: 0.316, data: 0.002) G_GAN: 2.593 G_L1: 25.277 D_real: 0.355 D_fake: 0.084 \n",
      "End of epoch 53 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 54, iters: 100, time: 0.110, data: 0.295) G_GAN: 2.986 G_L1: 32.429 D_real: 0.001 D_fake: 0.602 \n",
      "(epoch: 54, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.191 G_L1: 19.624 D_real: 0.022 D_fake: 1.224 \n",
      "(epoch: 54, iters: 300, time: 0.097, data: 0.002) G_GAN: 2.766 G_L1: 18.991 D_real: 0.074 D_fake: 0.389 \n",
      "(epoch: 54, iters: 400, time: 0.335, data: 0.002) G_GAN: 2.697 G_L1: 28.726 D_real: 0.115 D_fake: 0.222 \n",
      "End of epoch 54 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 55, iters: 100, time: 0.110, data: 0.267) G_GAN: 2.214 G_L1: 26.208 D_real: 0.289 D_fake: 0.302 \n",
      "(epoch: 55, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.196 G_L1: 23.695 D_real: 0.138 D_fake: 0.046 \n",
      "(epoch: 55, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.596 G_L1: 37.708 D_real: 0.022 D_fake: 0.065 \n",
      "(epoch: 55, iters: 400, time: 0.345, data: 0.002) G_GAN: 1.911 G_L1: 30.800 D_real: 0.168 D_fake: 0.300 \n",
      "saving the model at the end of epoch 55, iters 22000\n",
      "End of epoch 55 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.111, data: 0.283) G_GAN: 2.995 G_L1: 32.243 D_real: 0.049 D_fake: 0.070 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 56, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.286 G_L1: 30.825 D_real: 0.002 D_fake: 0.150 \n",
      "(epoch: 56, iters: 300, time: 0.114, data: 0.002) G_GAN: 3.038 G_L1: 26.467 D_real: 0.105 D_fake: 0.127 \n",
      "(epoch: 56, iters: 400, time: 0.350, data: 0.002) G_GAN: 2.383 G_L1: 28.596 D_real: 1.840 D_fake: 0.024 \n",
      "End of epoch 56 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 57, iters: 100, time: 0.111, data: 0.301) G_GAN: 2.112 G_L1: 24.776 D_real: 0.350 D_fake: 0.078 \n",
      "(epoch: 57, iters: 200, time: 0.110, data: 0.002) G_GAN: 2.932 G_L1: 34.285 D_real: 0.061 D_fake: 0.221 \n",
      "(epoch: 57, iters: 300, time: 0.114, data: 0.002) G_GAN: 0.873 G_L1: 22.995 D_real: 0.795 D_fake: 0.194 \n",
      "(epoch: 57, iters: 400, time: 0.336, data: 0.002) G_GAN: 1.813 G_L1: 31.756 D_real: 0.068 D_fake: 0.428 \n",
      "End of epoch 57 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 100, time: 0.112, data: 0.298) G_GAN: 3.039 G_L1: 32.071 D_real: 0.005 D_fake: 0.628 \n",
      "(epoch: 58, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.633 G_L1: 32.441 D_real: 0.013 D_fake: 0.978 \n",
      "(epoch: 58, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.726 G_L1: 34.053 D_real: 0.054 D_fake: 0.272 \n",
      "(epoch: 58, iters: 400, time: 0.358, data: 0.002) G_GAN: 0.862 G_L1: 26.107 D_real: 1.200 D_fake: 0.409 \n",
      "End of epoch 58 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 59, iters: 100, time: 0.113, data: 0.292) G_GAN: 1.949 G_L1: 20.613 D_real: 0.256 D_fake: 0.252 \n",
      "(epoch: 59, iters: 200, time: 0.108, data: 0.002) G_GAN: 1.620 G_L1: 22.835 D_real: 0.415 D_fake: 0.418 \n",
      "(epoch: 59, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.759 G_L1: 22.773 D_real: 0.482 D_fake: 0.648 \n",
      "(epoch: 59, iters: 400, time: 0.348, data: 0.002) G_GAN: 1.072 G_L1: 18.476 D_real: 0.602 D_fake: 0.114 \n",
      "End of epoch 59 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 60, iters: 100, time: 0.111, data: 0.267) G_GAN: 0.808 G_L1: 26.925 D_real: 1.467 D_fake: 0.219 \n",
      "(epoch: 60, iters: 200, time: 0.111, data: 0.002) G_GAN: 1.475 G_L1: 25.951 D_real: 1.096 D_fake: 0.072 \n",
      "(epoch: 60, iters: 300, time: 0.110, data: 0.002) G_GAN: 2.624 G_L1: 40.307 D_real: 0.020 D_fake: 0.122 \n",
      "(epoch: 60, iters: 400, time: 0.368, data: 0.002) G_GAN: 2.884 G_L1: 25.469 D_real: 0.014 D_fake: 0.524 \n",
      "saving the model at the end of epoch 60, iters 24000\n",
      "End of epoch 60 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.112, data: 0.286) G_GAN: 2.999 G_L1: 41.444 D_real: 0.001 D_fake: 0.087 \n",
      "(epoch: 61, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.366 G_L1: 37.063 D_real: 0.015 D_fake: 0.036 \n",
      "(epoch: 61, iters: 300, time: 0.111, data: 0.002) G_GAN: 5.544 G_L1: 34.964 D_real: 0.084 D_fake: 0.004 \n",
      "(epoch: 61, iters: 400, time: 0.442, data: 0.002) G_GAN: 2.758 G_L1: 26.733 D_real: 0.168 D_fake: 0.125 \n",
      "End of epoch 61 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 62, iters: 100, time: 0.112, data: 0.284) G_GAN: 2.882 G_L1: 25.120 D_real: 0.160 D_fake: 0.585 \n",
      "(epoch: 62, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.688 G_L1: 25.754 D_real: 0.055 D_fake: 0.128 \n",
      "(epoch: 62, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.839 G_L1: 25.987 D_real: 0.012 D_fake: 0.309 \n",
      "(epoch: 62, iters: 400, time: 0.346, data: 0.002) G_GAN: 3.794 G_L1: 26.878 D_real: 0.134 D_fake: 0.034 \n",
      "End of epoch 62 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 63, iters: 100, time: 0.112, data: 0.275) G_GAN: 4.329 G_L1: 26.361 D_real: 0.006 D_fake: 1.655 \n",
      "(epoch: 63, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.464 G_L1: 33.328 D_real: 0.037 D_fake: 0.042 \n",
      "saving the latest model (epoch 63, total_iters 25000)\n",
      "(epoch: 63, iters: 300, time: 0.110, data: 0.002) G_GAN: 3.570 G_L1: 25.692 D_real: 0.130 D_fake: 0.055 \n",
      "(epoch: 63, iters: 400, time: 0.352, data: 0.002) G_GAN: 2.692 G_L1: 26.496 D_real: 0.011 D_fake: 0.619 \n",
      "End of epoch 63 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 64, iters: 100, time: 0.112, data: 0.285) G_GAN: 2.721 G_L1: 25.042 D_real: 0.649 D_fake: 0.022 \n",
      "(epoch: 64, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.367 G_L1: 28.064 D_real: 0.224 D_fake: 0.369 \n",
      "(epoch: 64, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.097 G_L1: 24.261 D_real: 0.379 D_fake: 0.171 \n",
      "(epoch: 64, iters: 400, time: 0.369, data: 0.002) G_GAN: 2.918 G_L1: 30.581 D_real: 0.002 D_fake: 0.654 \n",
      "End of epoch 64 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 100, time: 0.113, data: 0.284) G_GAN: 2.116 G_L1: 26.244 D_real: 0.374 D_fake: 0.237 \n",
      "(epoch: 65, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.275 G_L1: 29.973 D_real: 0.023 D_fake: 0.130 \n",
      "(epoch: 65, iters: 300, time: 0.109, data: 0.002) G_GAN: 1.880 G_L1: 29.192 D_real: 0.998 D_fake: 0.056 \n",
      "(epoch: 65, iters: 400, time: 0.384, data: 0.002) G_GAN: 2.256 G_L1: 25.341 D_real: 1.759 D_fake: 0.022 \n",
      "saving the model at the end of epoch 65, iters 26000\n",
      "End of epoch 65 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.112, data: 0.301) G_GAN: 3.243 G_L1: 24.867 D_real: 1.203 D_fake: 0.023 \n",
      "(epoch: 66, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.799 G_L1: 25.038 D_real: 0.314 D_fake: 0.043 \n",
      "(epoch: 66, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.984 G_L1: 26.792 D_real: 0.505 D_fake: 0.156 \n",
      "(epoch: 66, iters: 400, time: 0.363, data: 0.002) G_GAN: 4.004 G_L1: 29.580 D_real: 0.001 D_fake: 0.038 \n",
      "End of epoch 66 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 67, iters: 100, time: 0.110, data: 0.279) G_GAN: 2.183 G_L1: 24.668 D_real: 0.370 D_fake: 0.158 \n",
      "(epoch: 67, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.387 G_L1: 23.047 D_real: 0.087 D_fake: 0.058 \n",
      "(epoch: 67, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.726 G_L1: 26.855 D_real: 0.083 D_fake: 0.107 \n",
      "(epoch: 67, iters: 400, time: 0.355, data: 0.002) G_GAN: 3.627 G_L1: 29.693 D_real: 0.036 D_fake: 0.048 \n",
      "End of epoch 67 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 68, iters: 100, time: 0.111, data: 0.275) G_GAN: 1.524 G_L1: 19.432 D_real: 0.651 D_fake: 0.110 \n",
      "(epoch: 68, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.849 G_L1: 24.850 D_real: 0.054 D_fake: 1.510 \n",
      "(epoch: 68, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.995 G_L1: 21.762 D_real: 0.035 D_fake: 0.515 \n",
      "(epoch: 68, iters: 400, time: 0.362, data: 0.002) G_GAN: 2.248 G_L1: 27.782 D_real: 0.544 D_fake: 0.061 \n",
      "End of epoch 68 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 69, iters: 100, time: 0.109, data: 0.291) G_GAN: 3.601 G_L1: 30.783 D_real: 0.003 D_fake: 0.045 \n",
      "(epoch: 69, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.537 G_L1: 27.153 D_real: 0.000 D_fake: 0.948 \n",
      "(epoch: 69, iters: 300, time: 0.114, data: 0.002) G_GAN: 2.852 G_L1: 23.813 D_real: 0.301 D_fake: 0.049 \n",
      "(epoch: 69, iters: 400, time: 0.373, data: 0.002) G_GAN: 3.260 G_L1: 26.695 D_real: 0.019 D_fake: 0.507 \n",
      "End of epoch 69 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 70, iters: 100, time: 0.109, data: 0.294) G_GAN: 1.037 G_L1: 19.584 D_real: 1.117 D_fake: 0.305 \n",
      "(epoch: 70, iters: 200, time: 0.114, data: 0.002) G_GAN: 2.638 G_L1: 18.478 D_real: 0.035 D_fake: 0.271 \n",
      "(epoch: 70, iters: 300, time: 0.109, data: 0.002) G_GAN: 1.996 G_L1: 27.171 D_real: 0.345 D_fake: 0.228 \n",
      "(epoch: 70, iters: 400, time: 0.376, data: 0.002) G_GAN: 2.951 G_L1: 32.657 D_real: 0.014 D_fake: 0.698 \n",
      "saving the model at the end of epoch 70, iters 28000\n",
      "End of epoch 70 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.114, data: 0.316) G_GAN: 0.768 G_L1: 22.702 D_real: 3.470 D_fake: 0.018 \n",
      "(epoch: 71, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.222 G_L1: 50.272 D_real: 0.000 D_fake: 1.016 \n",
      "(epoch: 71, iters: 300, time: 0.114, data: 0.002) G_GAN: 2.414 G_L1: 23.339 D_real: 0.137 D_fake: 0.190 \n",
      "(epoch: 71, iters: 400, time: 0.371, data: 0.002) G_GAN: 1.993 G_L1: 31.716 D_real: 0.539 D_fake: 0.075 \n",
      "End of epoch 71 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 72, iters: 100, time: 0.111, data: 0.290) G_GAN: 3.930 G_L1: 32.844 D_real: 0.006 D_fake: 0.040 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 72, iters: 200, time: 0.115, data: 0.002) G_GAN: 1.958 G_L1: 15.769 D_real: 0.542 D_fake: 0.059 \n",
      "(epoch: 72, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.428 G_L1: 19.897 D_real: 0.981 D_fake: 0.106 \n",
      "(epoch: 72, iters: 400, time: 0.497, data: 0.002) G_GAN: 2.919 G_L1: 32.424 D_real: 0.114 D_fake: 0.160 \n",
      "End of epoch 72 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 73, iters: 100, time: 0.113, data: 0.265) G_GAN: 2.796 G_L1: 26.657 D_real: 0.005 D_fake: 0.295 \n",
      "(epoch: 73, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.325 G_L1: 22.594 D_real: 0.432 D_fake: 0.288 \n",
      "(epoch: 73, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.702 G_L1: 22.742 D_real: 0.315 D_fake: 0.090 \n",
      "(epoch: 73, iters: 400, time: 0.350, data: 0.002) G_GAN: 3.636 G_L1: 29.958 D_real: 0.014 D_fake: 0.108 \n",
      "End of epoch 73 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 74, iters: 100, time: 0.112, data: 0.293) G_GAN: 3.079 G_L1: 31.339 D_real: 0.001 D_fake: 0.704 \n",
      "(epoch: 74, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.268 G_L1: 24.936 D_real: 0.088 D_fake: 0.138 \n",
      "(epoch: 74, iters: 300, time: 0.112, data: 0.002) G_GAN: 1.767 G_L1: 22.904 D_real: 0.631 D_fake: 0.819 \n",
      "(epoch: 74, iters: 400, time: 0.374, data: 0.002) G_GAN: 2.343 G_L1: 22.166 D_real: 0.020 D_fake: 0.609 \n",
      "End of epoch 74 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 78, iters: 100, time: 0.109, data: 0.285) G_GAN: 3.637 G_L1: 38.527 D_real: 0.003 D_fake: 0.043 \n",
      "(epoch: 78, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.655 G_L1: 26.779 D_real: 0.020 D_fake: 0.180 \n",
      "(epoch: 78, iters: 300, time: 0.110, data: 0.002) G_GAN: 5.394 G_L1: 27.957 D_real: 0.009 D_fake: 0.012 \n",
      "(epoch: 78, iters: 400, time: 0.381, data: 0.002) G_GAN: 0.870 G_L1: 20.257 D_real: 1.418 D_fake: 0.114 \n",
      "End of epoch 78 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 79, iters: 100, time: 0.111, data: 0.270) G_GAN: 3.918 G_L1: 36.084 D_real: 0.001 D_fake: 0.631 \n",
      "(epoch: 79, iters: 200, time: 0.110, data: 0.002) G_GAN: 2.291 G_L1: 24.785 D_real: 0.355 D_fake: 0.219 \n",
      "(epoch: 79, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.584 G_L1: 21.331 D_real: 0.707 D_fake: 0.192 \n",
      "(epoch: 79, iters: 400, time: 0.390, data: 0.002) G_GAN: 1.689 G_L1: 27.059 D_real: 0.763 D_fake: 0.109 \n",
      "End of epoch 79 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 80, iters: 100, time: 0.112, data: 0.284) G_GAN: 5.502 G_L1: 19.652 D_real: 0.005 D_fake: 1.273 \n",
      "(epoch: 80, iters: 200, time: 0.108, data: 0.002) G_GAN: 3.622 G_L1: 28.792 D_real: 0.000 D_fake: 1.213 \n",
      "(epoch: 80, iters: 300, time: 0.114, data: 0.002) G_GAN: 3.072 G_L1: 24.114 D_real: 0.109 D_fake: 0.061 \n",
      "(epoch: 80, iters: 400, time: 0.389, data: 0.002) G_GAN: 2.903 G_L1: 26.136 D_real: 0.184 D_fake: 0.469 \n",
      "saving the model at the end of epoch 80, iters 32000\n",
      "End of epoch 80 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.110, data: 0.307) G_GAN: 3.315 G_L1: 21.103 D_real: 0.088 D_fake: 0.722 \n",
      "(epoch: 81, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.599 G_L1: 26.150 D_real: 0.054 D_fake: 0.094 \n",
      "(epoch: 81, iters: 300, time: 0.115, data: 0.002) G_GAN: 2.455 G_L1: 27.822 D_real: 0.402 D_fake: 0.076 \n",
      "(epoch: 81, iters: 400, time: 0.524, data: 0.002) G_GAN: 4.119 G_L1: 32.125 D_real: 0.039 D_fake: 0.056 \n",
      "End of epoch 81 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 82, iters: 100, time: 0.113, data: 0.270) G_GAN: 2.310 G_L1: 20.889 D_real: 0.245 D_fake: 0.531 \n",
      "(epoch: 82, iters: 200, time: 0.113, data: 0.002) G_GAN: 4.240 G_L1: 25.560 D_real: 0.156 D_fake: 0.013 \n",
      "(epoch: 82, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.049 G_L1: 18.452 D_real: 0.482 D_fake: 0.148 \n",
      "(epoch: 82, iters: 400, time: 0.411, data: 0.002) G_GAN: 2.158 G_L1: 25.351 D_real: 1.736 D_fake: 0.028 \n",
      "End of epoch 82 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 100, time: 0.112, data: 0.287) G_GAN: 3.677 G_L1: 23.039 D_real: 0.122 D_fake: 1.127 \n",
      "(epoch: 83, iters: 200, time: 0.107, data: 0.002) G_GAN: 2.683 G_L1: 25.291 D_real: 0.299 D_fake: 0.047 \n",
      "(epoch: 83, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.850 G_L1: 27.495 D_real: 0.051 D_fake: 0.201 \n",
      "(epoch: 83, iters: 400, time: 0.403, data: 0.002) G_GAN: 3.435 G_L1: 25.851 D_real: 0.002 D_fake: 0.119 \n",
      "End of epoch 83 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 84, iters: 100, time: 0.111, data: 0.277) G_GAN: 3.385 G_L1: 24.200 D_real: 0.164 D_fake: 0.768 \n",
      "(epoch: 84, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.349 G_L1: 22.005 D_real: 0.150 D_fake: 0.367 \n",
      "(epoch: 84, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.043 G_L1: 26.222 D_real: 1.156 D_fake: 0.065 \n",
      "(epoch: 84, iters: 400, time: 0.406, data: 0.002) G_GAN: 3.734 G_L1: 25.771 D_real: 0.006 D_fake: 0.268 \n",
      "End of epoch 84 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 85, iters: 100, time: 0.112, data: 0.287) G_GAN: 2.385 G_L1: 19.133 D_real: 0.218 D_fake: 0.454 \n",
      "(epoch: 85, iters: 200, time: 0.109, data: 0.002) G_GAN: 3.025 G_L1: 20.201 D_real: 0.458 D_fake: 0.994 \n",
      "(epoch: 85, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.901 G_L1: 25.595 D_real: 3.331 D_fake: 0.053 \n",
      "(epoch: 85, iters: 400, time: 0.387, data: 0.002) G_GAN: 3.388 G_L1: 21.539 D_real: 0.004 D_fake: 4.501 \n",
      "saving the model at the end of epoch 85, iters 34000\n",
      "End of epoch 85 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.113, data: 0.310) G_GAN: 1.670 G_L1: 27.425 D_real: 0.167 D_fake: 0.245 \n",
      "(epoch: 86, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.147 G_L1: 23.464 D_real: 0.013 D_fake: 0.994 \n",
      "(epoch: 86, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.092 G_L1: 23.081 D_real: 0.631 D_fake: 0.320 \n",
      "(epoch: 86, iters: 400, time: 0.405, data: 0.002) G_GAN: 1.822 G_L1: 25.885 D_real: 0.321 D_fake: 0.536 \n",
      "End of epoch 86 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 87, iters: 100, time: 0.114, data: 0.274) G_GAN: 2.958 G_L1: 23.350 D_real: 0.072 D_fake: 0.401 \n",
      "(epoch: 87, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.505 G_L1: 21.787 D_real: 0.015 D_fake: 0.587 \n",
      "(epoch: 87, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.667 G_L1: 18.648 D_real: 0.168 D_fake: 0.142 \n",
      "(epoch: 87, iters: 400, time: 0.402, data: 0.002) G_GAN: 3.717 G_L1: 24.345 D_real: 0.037 D_fake: 0.029 \n",
      "End of epoch 87 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 88, iters: 100, time: 0.113, data: 0.291) G_GAN: 3.465 G_L1: 33.672 D_real: 0.012 D_fake: 0.092 \n",
      "(epoch: 88, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.842 G_L1: 26.335 D_real: 0.167 D_fake: 0.172 \n",
      "saving the latest model (epoch 88, total_iters 35000)\n",
      "(epoch: 88, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.938 G_L1: 34.387 D_real: 0.066 D_fake: 0.068 \n",
      "(epoch: 88, iters: 400, time: 0.395, data: 0.002) G_GAN: 2.193 G_L1: 22.547 D_real: 0.300 D_fake: 0.397 \n",
      "End of epoch 88 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 89, iters: 100, time: 0.113, data: 0.281) G_GAN: 2.619 G_L1: 26.510 D_real: 0.171 D_fake: 0.388 \n",
      "(epoch: 89, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.663 G_L1: 22.660 D_real: 0.091 D_fake: 0.146 \n",
      "(epoch: 89, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.796 G_L1: 31.415 D_real: 0.048 D_fake: 0.797 \n",
      "(epoch: 89, iters: 400, time: 0.407, data: 0.002) G_GAN: 3.224 G_L1: 29.807 D_real: 0.070 D_fake: 0.910 \n",
      "End of epoch 89 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 100, time: 0.112, data: 0.293) G_GAN: 3.297 G_L1: 23.888 D_real: 0.298 D_fake: 0.034 \n",
      "(epoch: 90, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.129 G_L1: 24.085 D_real: 0.297 D_fake: 0.080 \n",
      "(epoch: 90, iters: 300, time: 0.112, data: 0.003) G_GAN: 2.956 G_L1: 26.082 D_real: 0.121 D_fake: 0.157 \n",
      "(epoch: 90, iters: 400, time: 0.511, data: 0.002) G_GAN: 3.127 G_L1: 29.720 D_real: 0.036 D_fake: 0.243 \n",
      "saving the model at the end of epoch 90, iters 36000\n",
      "End of epoch 90 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.107, data: 0.319) G_GAN: 2.833 G_L1: 21.555 D_real: 0.302 D_fake: 0.043 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 91, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.695 G_L1: 33.287 D_real: 0.006 D_fake: 0.210 \n",
      "(epoch: 91, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.760 G_L1: 19.607 D_real: 0.167 D_fake: 0.161 \n",
      "(epoch: 91, iters: 400, time: 0.424, data: 0.002) G_GAN: 1.838 G_L1: 22.762 D_real: 0.281 D_fake: 0.126 \n",
      "End of epoch 91 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 92, iters: 100, time: 0.113, data: 0.276) G_GAN: 2.889 G_L1: 26.121 D_real: 0.018 D_fake: 0.500 \n",
      "(epoch: 92, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.293 G_L1: 24.042 D_real: 0.004 D_fake: 1.016 \n",
      "(epoch: 92, iters: 300, time: 0.114, data: 0.002) G_GAN: 3.006 G_L1: 29.009 D_real: 0.449 D_fake: 0.046 \n",
      "(epoch: 92, iters: 400, time: 0.432, data: 0.002) G_GAN: 4.402 G_L1: 29.105 D_real: 0.076 D_fake: 0.064 \n",
      "End of epoch 92 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 100, time: 0.111, data: 0.283) G_GAN: 3.954 G_L1: 26.791 D_real: 0.002 D_fake: 0.778 \n",
      "(epoch: 93, iters: 200, time: 0.113, data: 0.002) G_GAN: 0.503 G_L1: 18.981 D_real: 0.767 D_fake: 0.415 \n",
      "(epoch: 93, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.519 G_L1: 24.124 D_real: 0.067 D_fake: 0.077 \n",
      "(epoch: 93, iters: 400, time: 0.430, data: 0.002) G_GAN: 3.639 G_L1: 30.904 D_real: 0.010 D_fake: 0.220 \n",
      "End of epoch 93 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 94, iters: 100, time: 0.112, data: 0.275) G_GAN: 3.810 G_L1: 32.568 D_real: 0.149 D_fake: 0.064 \n",
      "(epoch: 94, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.790 G_L1: 25.033 D_real: 0.007 D_fake: 0.466 \n",
      "(epoch: 94, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.072 G_L1: 31.391 D_real: 0.009 D_fake: 0.331 \n",
      "(epoch: 94, iters: 400, time: 0.418, data: 0.002) G_GAN: 3.782 G_L1: 28.789 D_real: 0.172 D_fake: 0.073 \n",
      "End of epoch 94 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 95, iters: 100, time: 0.112, data: 0.275) G_GAN: 3.040 G_L1: 18.078 D_real: 0.232 D_fake: 0.041 \n",
      "(epoch: 95, iters: 200, time: 0.114, data: 0.002) G_GAN: 1.563 G_L1: 26.436 D_real: 0.165 D_fake: 0.039 \n",
      "(epoch: 95, iters: 300, time: 0.114, data: 0.003) G_GAN: 2.333 G_L1: 22.963 D_real: 0.287 D_fake: 0.093 \n",
      "(epoch: 95, iters: 400, time: 0.426, data: 0.002) G_GAN: 3.142 G_L1: 21.266 D_real: 0.039 D_fake: 0.099 \n",
      "saving the model at the end of epoch 95, iters 38000\n",
      "End of epoch 95 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.112, data: 0.269) G_GAN: 4.799 G_L1: 33.605 D_real: 0.007 D_fake: 0.018 \n",
      "(epoch: 96, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.190 G_L1: 20.527 D_real: 0.232 D_fake: 0.258 \n",
      "(epoch: 96, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.678 G_L1: 17.129 D_real: 0.820 D_fake: 0.034 \n",
      "(epoch: 96, iters: 400, time: 0.432, data: 0.002) G_GAN: 2.300 G_L1: 20.647 D_real: 0.234 D_fake: 0.153 \n",
      "End of epoch 96 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 97, iters: 100, time: 0.113, data: 0.293) G_GAN: 2.730 G_L1: 19.994 D_real: 0.414 D_fake: 0.099 \n",
      "(epoch: 97, iters: 200, time: 0.105, data: 0.002) G_GAN: 2.036 G_L1: 27.217 D_real: 0.579 D_fake: 0.036 \n",
      "(epoch: 97, iters: 300, time: 0.112, data: 0.002) G_GAN: 1.391 G_L1: 20.294 D_real: 0.670 D_fake: 0.231 \n",
      "(epoch: 97, iters: 400, time: 0.426, data: 0.002) G_GAN: 3.783 G_L1: 20.764 D_real: 0.007 D_fake: 0.482 \n",
      "End of epoch 97 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 98, iters: 100, time: 0.113, data: 0.269) G_GAN: 4.087 G_L1: 24.806 D_real: 0.082 D_fake: 0.030 \n",
      "(epoch: 98, iters: 200, time: 0.113, data: 0.002) G_GAN: 1.550 G_L1: 21.143 D_real: 0.723 D_fake: 0.078 \n",
      "(epoch: 98, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.188 G_L1: 22.870 D_real: 0.028 D_fake: 0.452 \n",
      "(epoch: 98, iters: 400, time: 0.532, data: 0.002) G_GAN: 1.299 G_L1: 26.604 D_real: 1.940 D_fake: 0.032 \n",
      "End of epoch 98 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 99, iters: 100, time: 0.115, data: 0.278) G_GAN: 3.817 G_L1: 22.574 D_real: 0.017 D_fake: 0.090 \n",
      "(epoch: 99, iters: 200, time: 0.111, data: 0.002) G_GAN: 7.355 G_L1: 33.327 D_real: 0.010 D_fake: 1.164 \n",
      "(epoch: 99, iters: 300, time: 0.114, data: 0.002) G_GAN: 4.685 G_L1: 28.101 D_real: 0.038 D_fake: 0.042 \n",
      "(epoch: 99, iters: 400, time: 0.427, data: 0.002) G_GAN: 1.510 G_L1: 23.352 D_real: 1.066 D_fake: 0.070 \n",
      "End of epoch 99 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 100, time: 0.112, data: 0.267) G_GAN: 1.614 G_L1: 21.241 D_real: 1.375 D_fake: 0.035 \n",
      "(epoch: 100, iters: 200, time: 0.111, data: 0.002) G_GAN: 4.424 G_L1: 34.713 D_real: 0.002 D_fake: 0.901 \n",
      "(epoch: 100, iters: 300, time: 0.115, data: 0.002) G_GAN: 1.494 G_L1: 17.590 D_real: 0.686 D_fake: 0.057 \n",
      "(epoch: 100, iters: 400, time: 0.455, data: 0.002) G_GAN: 3.712 G_L1: 24.345 D_real: 0.029 D_fake: 0.295 \n",
      "saving the latest model (epoch 100, total_iters 40000)\n",
      "saving the model at the end of epoch 100, iters 40000\n",
      "End of epoch 100 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "(epoch: 101, iters: 100, time: 0.113, data: 0.291) G_GAN: 3.373 G_L1: 26.916 D_real: 0.117 D_fake: 0.341 \n",
      "(epoch: 101, iters: 200, time: 0.111, data: 0.002) G_GAN: 4.905 G_L1: 17.536 D_real: 0.006 D_fake: 1.291 \n",
      "(epoch: 101, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.788 G_L1: 32.757 D_real: 0.092 D_fake: 0.624 \n",
      "(epoch: 101, iters: 400, time: 0.452, data: 0.002) G_GAN: 2.129 G_L1: 19.440 D_real: 0.407 D_fake: 0.110 \n",
      "End of epoch 101 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "(epoch: 102, iters: 100, time: 0.115, data: 0.275) G_GAN: 2.069 G_L1: 18.385 D_real: 0.382 D_fake: 0.192 \n",
      "(epoch: 102, iters: 200, time: 0.114, data: 0.002) G_GAN: 4.110 G_L1: 25.315 D_real: 0.095 D_fake: 1.380 \n",
      "(epoch: 102, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.709 G_L1: 21.697 D_real: 0.193 D_fake: 0.149 \n",
      "(epoch: 102, iters: 400, time: 0.429, data: 0.002) G_GAN: 1.749 G_L1: 20.544 D_real: 0.686 D_fake: 0.700 \n",
      "End of epoch 102 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "(epoch: 103, iters: 100, time: 0.111, data: 0.269) G_GAN: 1.524 G_L1: 16.508 D_real: 0.578 D_fake: 0.125 \n",
      "(epoch: 103, iters: 200, time: 0.113, data: 0.002) G_GAN: 4.350 G_L1: 21.471 D_real: 0.197 D_fake: 0.019 \n",
      "(epoch: 103, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.475 G_L1: 23.799 D_real: 0.073 D_fake: 0.039 \n",
      "(epoch: 103, iters: 400, time: 0.434, data: 0.002) G_GAN: 3.628 G_L1: 19.136 D_real: 0.106 D_fake: 0.345 \n",
      "End of epoch 103 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "(epoch: 104, iters: 100, time: 0.113, data: 0.288) G_GAN: 2.735 G_L1: 28.076 D_real: 0.096 D_fake: 0.086 \n",
      "(epoch: 104, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.561 G_L1: 28.602 D_real: 0.006 D_fake: 0.114 \n",
      "(epoch: 104, iters: 300, time: 0.110, data: 0.002) G_GAN: 3.286 G_L1: 18.397 D_real: 0.042 D_fake: 0.202 \n",
      "(epoch: 104, iters: 400, time: 0.452, data: 0.002) G_GAN: 4.127 G_L1: 33.648 D_real: 0.012 D_fake: 0.041 \n",
      "End of epoch 104 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "(epoch: 105, iters: 100, time: 0.113, data: 0.271) G_GAN: 4.327 G_L1: 26.492 D_real: 0.089 D_fake: 0.035 \n",
      "(epoch: 105, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.224 G_L1: 24.053 D_real: 0.039 D_fake: 0.840 \n",
      "(epoch: 105, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.535 G_L1: 27.231 D_real: 0.279 D_fake: 0.013 \n",
      "(epoch: 105, iters: 400, time: 0.515, data: 0.002) G_GAN: 2.756 G_L1: 24.506 D_real: 0.021 D_fake: 0.241 \n",
      "saving the model at the end of epoch 105, iters 42000\n",
      "End of epoch 105 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "(epoch: 106, iters: 100, time: 0.110, data: 0.275) G_GAN: 4.333 G_L1: 26.755 D_real: 0.076 D_fake: 0.294 \n",
      "(epoch: 106, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.747 G_L1: 28.046 D_real: 0.079 D_fake: 0.085 \n",
      "(epoch: 106, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.616 G_L1: 31.782 D_real: 0.377 D_fake: 0.028 \n",
      "(epoch: 106, iters: 400, time: 0.445, data: 0.002) G_GAN: 1.863 G_L1: 23.685 D_real: 0.734 D_fake: 0.153 \n",
      "End of epoch 106 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "(epoch: 107, iters: 100, time: 0.112, data: 0.285) G_GAN: 4.896 G_L1: 21.564 D_real: 0.002 D_fake: 1.210 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 107, iters: 200, time: 0.112, data: 0.003) G_GAN: 3.393 G_L1: 26.963 D_real: 0.306 D_fake: 0.033 \n",
      "(epoch: 107, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.219 G_L1: 26.454 D_real: 0.178 D_fake: 0.206 \n",
      "(epoch: 107, iters: 400, time: 0.446, data: 0.002) G_GAN: 3.844 G_L1: 19.283 D_real: 0.092 D_fake: 0.075 \n",
      "End of epoch 107 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "(epoch: 108, iters: 100, time: 0.111, data: 0.306) G_GAN: 3.398 G_L1: 20.269 D_real: 0.133 D_fake: 0.107 \n",
      "(epoch: 108, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.741 G_L1: 18.334 D_real: 0.112 D_fake: 0.061 \n",
      "(epoch: 108, iters: 300, time: 0.112, data: 0.002) G_GAN: 5.141 G_L1: 25.016 D_real: 0.040 D_fake: 0.015 \n",
      "(epoch: 108, iters: 400, time: 0.442, data: 0.002) G_GAN: 1.853 G_L1: 20.398 D_real: 0.100 D_fake: 0.372 \n",
      "End of epoch 108 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "(epoch: 109, iters: 100, time: 0.112, data: 0.283) G_GAN: 2.274 G_L1: 18.068 D_real: 0.314 D_fake: 0.080 \n",
      "(epoch: 109, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.522 G_L1: 24.642 D_real: 0.027 D_fake: 0.095 \n",
      "(epoch: 109, iters: 300, time: 0.112, data: 0.002) G_GAN: 1.209 G_L1: 20.689 D_real: 1.651 D_fake: 0.021 \n",
      "(epoch: 109, iters: 400, time: 0.439, data: 0.002) G_GAN: 2.737 G_L1: 23.798 D_real: 0.125 D_fake: 0.142 \n",
      "End of epoch 109 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "(epoch: 110, iters: 100, time: 0.112, data: 0.287) G_GAN: 3.142 G_L1: 24.545 D_real: 0.063 D_fake: 0.047 \n",
      "(epoch: 110, iters: 200, time: 0.113, data: 0.002) G_GAN: 5.174 G_L1: 20.847 D_real: 1.292 D_fake: 0.001 \n",
      "(epoch: 110, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.333 G_L1: 21.772 D_real: 0.516 D_fake: 0.045 \n",
      "(epoch: 110, iters: 400, time: 0.449, data: 0.002) G_GAN: 1.692 G_L1: 22.478 D_real: 0.436 D_fake: 0.102 \n",
      "saving the model at the end of epoch 110, iters 44000\n",
      "End of epoch 110 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "(epoch: 111, iters: 100, time: 0.112, data: 0.290) G_GAN: 2.815 G_L1: 19.222 D_real: 0.312 D_fake: 0.240 \n",
      "(epoch: 111, iters: 200, time: 0.114, data: 0.002) G_GAN: 2.865 G_L1: 21.852 D_real: 0.060 D_fake: 0.118 \n",
      "(epoch: 111, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.095 G_L1: 19.075 D_real: 0.651 D_fake: 0.117 \n",
      "(epoch: 111, iters: 400, time: 0.466, data: 0.002) G_GAN: 3.133 G_L1: 21.327 D_real: 0.030 D_fake: 0.502 \n",
      "End of epoch 111 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "(epoch: 112, iters: 100, time: 0.113, data: 0.299) G_GAN: 5.360 G_L1: 29.583 D_real: 0.194 D_fake: 0.009 \n",
      "(epoch: 112, iters: 200, time: 0.111, data: 0.002) G_GAN: 5.130 G_L1: 25.233 D_real: 0.024 D_fake: 0.016 \n",
      "(epoch: 112, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.878 G_L1: 24.904 D_real: 0.037 D_fake: 0.242 \n",
      "(epoch: 112, iters: 400, time: 0.552, data: 0.002) G_GAN: 1.324 G_L1: 13.894 D_real: 0.405 D_fake: 0.096 \n",
      "End of epoch 112 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "(epoch: 113, iters: 100, time: 0.109, data: 0.285) G_GAN: 3.992 G_L1: 29.805 D_real: 0.022 D_fake: 0.783 \n",
      "(epoch: 113, iters: 200, time: 0.112, data: 0.003) G_GAN: 6.545 G_L1: 31.734 D_real: 0.140 D_fake: 0.002 \n",
      "saving the latest model (epoch 113, total_iters 45000)\n",
      "(epoch: 113, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.674 G_L1: 19.707 D_real: 1.439 D_fake: 0.013 \n",
      "(epoch: 113, iters: 400, time: 0.448, data: 0.002) G_GAN: 4.024 G_L1: 25.968 D_real: 0.008 D_fake: 0.317 \n",
      "End of epoch 113 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "(epoch: 114, iters: 100, time: 0.113, data: 0.279) G_GAN: 3.229 G_L1: 20.944 D_real: 0.014 D_fake: 0.455 \n",
      "(epoch: 114, iters: 200, time: 0.108, data: 0.002) G_GAN: 4.251 G_L1: 22.456 D_real: 0.247 D_fake: 0.012 \n",
      "(epoch: 114, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.055 G_L1: 19.316 D_real: 0.320 D_fake: 0.078 \n",
      "(epoch: 114, iters: 400, time: 0.433, data: 0.002) G_GAN: 4.010 G_L1: 31.918 D_real: 0.093 D_fake: 0.077 \n",
      "End of epoch 114 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "(epoch: 115, iters: 100, time: 0.113, data: 0.285) G_GAN: 2.057 G_L1: 20.799 D_real: 0.228 D_fake: 0.187 \n",
      "(epoch: 115, iters: 200, time: 0.110, data: 0.002) G_GAN: 1.983 G_L1: 17.681 D_real: 0.344 D_fake: 0.353 \n",
      "(epoch: 115, iters: 300, time: 0.106, data: 0.002) G_GAN: 3.404 G_L1: 18.462 D_real: 0.339 D_fake: 0.051 \n",
      "(epoch: 115, iters: 400, time: 0.461, data: 0.002) G_GAN: 3.900 G_L1: 21.928 D_real: 0.301 D_fake: 0.016 \n",
      "saving the model at the end of epoch 115, iters 46000\n",
      "End of epoch 115 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "(epoch: 116, iters: 100, time: 0.113, data: 0.294) G_GAN: 1.378 G_L1: 21.758 D_real: 0.797 D_fake: 0.160 \n",
      "(epoch: 116, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.305 G_L1: 25.346 D_real: 0.043 D_fake: 0.090 \n",
      "(epoch: 116, iters: 300, time: 0.114, data: 0.002) G_GAN: 4.959 G_L1: 26.575 D_real: 0.042 D_fake: 0.048 \n",
      "(epoch: 116, iters: 400, time: 0.461, data: 0.002) G_GAN: 3.856 G_L1: 21.166 D_real: 0.033 D_fake: 0.070 \n",
      "End of epoch 116 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "(epoch: 117, iters: 100, time: 0.113, data: 0.260) G_GAN: 2.618 G_L1: 23.644 D_real: 0.100 D_fake: 0.283 \n",
      "(epoch: 117, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.328 G_L1: 22.350 D_real: 0.269 D_fake: 0.442 \n",
      "(epoch: 117, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.574 G_L1: 16.803 D_real: 0.014 D_fake: 0.095 \n",
      "(epoch: 117, iters: 400, time: 0.464, data: 0.002) G_GAN: 1.834 G_L1: 20.885 D_real: 0.052 D_fake: 0.260 \n",
      "End of epoch 117 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "(epoch: 118, iters: 100, time: 0.113, data: 0.276) G_GAN: 2.266 G_L1: 17.678 D_real: 0.273 D_fake: 0.197 \n",
      "(epoch: 118, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.314 G_L1: 22.205 D_real: 0.280 D_fake: 0.080 \n",
      "(epoch: 118, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.558 G_L1: 21.848 D_real: 0.004 D_fake: 0.700 \n",
      "(epoch: 118, iters: 400, time: 0.533, data: 0.002) G_GAN: 3.611 G_L1: 16.469 D_real: 0.200 D_fake: 0.042 \n",
      "End of epoch 118 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "(epoch: 119, iters: 100, time: 0.111, data: 0.279) G_GAN: 4.535 G_L1: 21.154 D_real: 0.039 D_fake: 0.018 \n",
      "(epoch: 119, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.904 G_L1: 25.153 D_real: 0.016 D_fake: 0.377 \n",
      "(epoch: 119, iters: 300, time: 0.114, data: 0.002) G_GAN: 3.094 G_L1: 27.203 D_real: 0.617 D_fake: 0.035 \n",
      "(epoch: 119, iters: 400, time: 0.461, data: 0.002) G_GAN: 3.586 G_L1: 26.039 D_real: 0.217 D_fake: 0.023 \n",
      "End of epoch 119 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "(epoch: 120, iters: 100, time: 0.115, data: 0.308) G_GAN: 3.587 G_L1: 27.699 D_real: 0.009 D_fake: 0.129 \n",
      "(epoch: 120, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.284 G_L1: 18.659 D_real: 0.161 D_fake: 0.366 \n",
      "(epoch: 120, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.291 G_L1: 21.378 D_real: 0.020 D_fake: 0.381 \n",
      "(epoch: 120, iters: 400, time: 0.477, data: 0.002) G_GAN: 1.996 G_L1: 20.436 D_real: 0.478 D_fake: 0.095 \n",
      "saving the model at the end of epoch 120, iters 48000\n",
      "End of epoch 120 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "(epoch: 121, iters: 100, time: 0.113, data: 0.282) G_GAN: 4.716 G_L1: 21.467 D_real: 0.076 D_fake: 0.012 \n",
      "(epoch: 121, iters: 200, time: 0.114, data: 0.002) G_GAN: 2.788 G_L1: 21.700 D_real: 0.066 D_fake: 0.163 \n",
      "(epoch: 121, iters: 300, time: 0.114, data: 0.002) G_GAN: 4.094 G_L1: 24.779 D_real: 0.010 D_fake: 0.583 \n",
      "(epoch: 121, iters: 400, time: 0.489, data: 0.002) G_GAN: 2.850 G_L1: 23.453 D_real: 0.109 D_fake: 0.071 \n",
      "End of epoch 121 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "(epoch: 122, iters: 100, time: 0.114, data: 0.302) G_GAN: 2.657 G_L1: 19.409 D_real: 0.346 D_fake: 0.099 \n",
      "(epoch: 122, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.545 G_L1: 23.656 D_real: 0.197 D_fake: 0.131 \n",
      "(epoch: 122, iters: 300, time: 0.108, data: 0.002) G_GAN: 2.911 G_L1: 19.132 D_real: 0.105 D_fake: 0.087 \n",
      "(epoch: 122, iters: 400, time: 0.468, data: 0.002) G_GAN: 2.424 G_L1: 19.495 D_real: 0.229 D_fake: 0.086 \n",
      "End of epoch 122 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "(epoch: 123, iters: 100, time: 0.107, data: 0.294) G_GAN: 1.192 G_L1: 20.239 D_real: 0.532 D_fake: 0.112 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 123, iters: 200, time: 0.110, data: 0.002) G_GAN: 4.405 G_L1: 21.328 D_real: 0.199 D_fake: 0.022 \n",
      "(epoch: 123, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.996 G_L1: 19.948 D_real: 0.005 D_fake: 1.100 \n",
      "(epoch: 123, iters: 400, time: 0.473, data: 0.002) G_GAN: 3.522 G_L1: 19.636 D_real: 0.108 D_fake: 0.049 \n",
      "End of epoch 123 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "(epoch: 124, iters: 100, time: 0.112, data: 0.284) G_GAN: 4.538 G_L1: 17.388 D_real: 0.236 D_fake: 0.010 \n",
      "(epoch: 124, iters: 200, time: 0.113, data: 0.002) G_GAN: 4.581 G_L1: 33.216 D_real: 0.076 D_fake: 0.017 \n",
      "(epoch: 124, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.585 G_L1: 16.551 D_real: 0.026 D_fake: 0.343 \n",
      "(epoch: 124, iters: 400, time: 0.582, data: 0.002) G_GAN: 3.165 G_L1: 17.526 D_real: 0.173 D_fake: 0.137 \n",
      "End of epoch 124 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "(epoch: 125, iters: 100, time: 0.111, data: 0.279) G_GAN: 4.903 G_L1: 30.871 D_real: 0.124 D_fake: 0.369 \n",
      "(epoch: 125, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.552 G_L1: 19.919 D_real: 0.015 D_fake: 0.420 \n",
      "(epoch: 125, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.481 G_L1: 24.599 D_real: 0.013 D_fake: 0.149 \n",
      "(epoch: 125, iters: 400, time: 0.475, data: 0.002) G_GAN: 2.743 G_L1: 18.756 D_real: 0.099 D_fake: 0.150 \n",
      "saving the latest model (epoch 125, total_iters 50000)\n",
      "saving the model at the end of epoch 125, iters 50000\n",
      "End of epoch 125 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "(epoch: 126, iters: 100, time: 0.113, data: 0.285) G_GAN: 5.335 G_L1: 16.709 D_real: 0.009 D_fake: 1.700 \n",
      "(epoch: 126, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.196 G_L1: 21.608 D_real: 0.360 D_fake: 0.099 \n",
      "(epoch: 126, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.807 G_L1: 24.609 D_real: 0.000 D_fake: 0.526 \n",
      "(epoch: 126, iters: 400, time: 0.484, data: 0.002) G_GAN: 4.731 G_L1: 27.658 D_real: 0.077 D_fake: 0.018 \n",
      "End of epoch 126 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "(epoch: 127, iters: 100, time: 0.114, data: 0.269) G_GAN: 3.523 G_L1: 17.673 D_real: 0.034 D_fake: 0.081 \n",
      "(epoch: 127, iters: 200, time: 0.114, data: 0.002) G_GAN: 1.755 G_L1: 14.580 D_real: 0.324 D_fake: 0.161 \n",
      "(epoch: 127, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.216 G_L1: 24.816 D_real: 0.063 D_fake: 0.113 \n",
      "(epoch: 127, iters: 400, time: 0.479, data: 0.002) G_GAN: 3.138 G_L1: 23.550 D_real: 0.001 D_fake: 0.478 \n",
      "End of epoch 127 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "(epoch: 128, iters: 100, time: 0.113, data: 0.280) G_GAN: 4.038 G_L1: 18.791 D_real: 0.016 D_fake: 0.898 \n",
      "(epoch: 128, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.547 G_L1: 21.550 D_real: 0.009 D_fake: 0.308 \n",
      "(epoch: 128, iters: 300, time: 0.111, data: 0.002) G_GAN: 3.515 G_L1: 28.709 D_real: 0.005 D_fake: 0.249 \n",
      "(epoch: 128, iters: 400, time: 0.488, data: 0.002) G_GAN: 5.967 G_L1: 25.514 D_real: 0.009 D_fake: 1.120 \n",
      "End of epoch 128 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "(epoch: 129, iters: 100, time: 0.111, data: 0.270) G_GAN: 3.045 G_L1: 16.370 D_real: 0.036 D_fake: 0.593 \n",
      "(epoch: 129, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.278 G_L1: 26.501 D_real: 0.036 D_fake: 0.316 \n",
      "(epoch: 129, iters: 300, time: 0.111, data: 0.002) G_GAN: 3.017 G_L1: 21.383 D_real: 1.002 D_fake: 0.009 \n",
      "(epoch: 129, iters: 400, time: 0.476, data: 0.002) G_GAN: 3.449 G_L1: 20.652 D_real: 0.052 D_fake: 0.140 \n",
      "End of epoch 129 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "(epoch: 130, iters: 100, time: 0.112, data: 0.325) G_GAN: 2.569 G_L1: 22.473 D_real: 0.026 D_fake: 0.225 \n",
      "(epoch: 130, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.269 G_L1: 20.329 D_real: 0.028 D_fake: 0.215 \n",
      "(epoch: 130, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.695 G_L1: 21.537 D_real: 0.031 D_fake: 0.569 \n",
      "(epoch: 130, iters: 400, time: 0.588, data: 0.002) G_GAN: 4.190 G_L1: 23.569 D_real: 0.029 D_fake: 0.912 \n",
      "saving the model at the end of epoch 130, iters 52000\n",
      "End of epoch 130 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "(epoch: 131, iters: 100, time: 0.112, data: 0.301) G_GAN: 3.834 G_L1: 30.691 D_real: 0.001 D_fake: 0.060 \n",
      "(epoch: 131, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.231 G_L1: 20.781 D_real: 0.004 D_fake: 0.322 \n",
      "(epoch: 131, iters: 300, time: 0.113, data: 0.002) G_GAN: 1.018 G_L1: 21.806 D_real: 0.994 D_fake: 0.032 \n",
      "(epoch: 131, iters: 400, time: 0.514, data: 0.002) G_GAN: 3.599 G_L1: 15.723 D_real: 0.056 D_fake: 0.198 \n",
      "End of epoch 131 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "(epoch: 132, iters: 100, time: 0.113, data: 0.325) G_GAN: 0.736 G_L1: 16.168 D_real: 0.772 D_fake: 0.089 \n",
      "(epoch: 132, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.990 G_L1: 28.485 D_real: 0.005 D_fake: 0.089 \n",
      "(epoch: 132, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.544 G_L1: 16.784 D_real: 0.798 D_fake: 0.025 \n",
      "(epoch: 132, iters: 400, time: 0.487, data: 0.002) G_GAN: 5.175 G_L1: 22.941 D_real: 0.138 D_fake: 0.012 \n",
      "End of epoch 132 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "(epoch: 133, iters: 100, time: 0.112, data: 0.288) G_GAN: 3.382 G_L1: 18.659 D_real: 0.638 D_fake: 0.040 \n",
      "(epoch: 133, iters: 200, time: 0.110, data: 0.002) G_GAN: 2.795 G_L1: 22.272 D_real: 0.093 D_fake: 0.239 \n",
      "(epoch: 133, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.554 G_L1: 17.693 D_real: 0.040 D_fake: 0.651 \n",
      "(epoch: 133, iters: 400, time: 0.499, data: 0.002) G_GAN: 3.465 G_L1: 18.552 D_real: 0.237 D_fake: 0.019 \n",
      "End of epoch 133 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "(epoch: 134, iters: 100, time: 0.111, data: 0.302) G_GAN: 4.542 G_L1: 20.322 D_real: 0.015 D_fake: 0.651 \n",
      "(epoch: 134, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.954 G_L1: 18.743 D_real: 0.048 D_fake: 0.118 \n",
      "(epoch: 134, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.185 G_L1: 33.802 D_real: 0.001 D_fake: 0.108 \n",
      "(epoch: 134, iters: 400, time: 0.503, data: 0.002) G_GAN: 3.017 G_L1: 19.004 D_real: 0.076 D_fake: 0.131 \n",
      "End of epoch 134 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "(epoch: 135, iters: 100, time: 0.111, data: 0.284) G_GAN: 2.297 G_L1: 15.074 D_real: 0.328 D_fake: 0.064 \n",
      "(epoch: 135, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.348 G_L1: 23.531 D_real: 0.016 D_fake: 0.073 \n",
      "(epoch: 135, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.827 G_L1: 16.687 D_real: 1.009 D_fake: 0.013 \n",
      "(epoch: 135, iters: 400, time: 0.503, data: 0.002) G_GAN: 2.560 G_L1: 16.717 D_real: 0.322 D_fake: 0.221 \n",
      "saving the model at the end of epoch 135, iters 54000\n",
      "End of epoch 135 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "(epoch: 136, iters: 100, time: 0.109, data: 0.313) G_GAN: 4.507 G_L1: 18.686 D_real: 0.146 D_fake: 0.014 \n",
      "(epoch: 136, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.946 G_L1: 16.041 D_real: 0.124 D_fake: 0.028 \n",
      "(epoch: 136, iters: 300, time: 0.114, data: 0.002) G_GAN: 0.796 G_L1: 23.413 D_real: 1.148 D_fake: 0.065 \n",
      "(epoch: 136, iters: 400, time: 0.606, data: 0.002) G_GAN: 3.203 G_L1: 25.069 D_real: 0.066 D_fake: 0.280 \n",
      "End of epoch 136 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "(epoch: 137, iters: 100, time: 0.111, data: 0.291) G_GAN: 2.768 G_L1: 23.370 D_real: 0.050 D_fake: 0.121 \n",
      "(epoch: 137, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.672 G_L1: 24.211 D_real: 0.030 D_fake: 0.248 \n",
      "(epoch: 137, iters: 300, time: 0.107, data: 0.002) G_GAN: 5.328 G_L1: 21.712 D_real: 0.151 D_fake: 0.551 \n",
      "(epoch: 137, iters: 400, time: 0.531, data: 0.002) G_GAN: 2.265 G_L1: 18.702 D_real: 0.385 D_fake: 0.172 \n",
      "End of epoch 137 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "(epoch: 138, iters: 100, time: 0.114, data: 0.277) G_GAN: 3.745 G_L1: 17.776 D_real: 0.032 D_fake: 0.265 \n",
      "(epoch: 138, iters: 200, time: 0.112, data: 0.002) G_GAN: 5.914 G_L1: 23.212 D_real: 0.019 D_fake: 0.013 \n",
      "saving the latest model (epoch 138, total_iters 55000)\n",
      "(epoch: 138, iters: 300, time: 0.110, data: 0.002) G_GAN: 3.356 G_L1: 22.743 D_real: 0.048 D_fake: 0.529 \n",
      "(epoch: 138, iters: 400, time: 0.506, data: 0.002) G_GAN: 3.335 G_L1: 23.483 D_real: 0.034 D_fake: 0.170 \n",
      "End of epoch 138 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 139, iters: 100, time: 0.107, data: 0.270) G_GAN: 2.972 G_L1: 17.683 D_real: 0.025 D_fake: 0.266 \n",
      "(epoch: 139, iters: 200, time: 0.106, data: 0.002) G_GAN: 2.897 G_L1: 18.694 D_real: 0.449 D_fake: 0.023 \n",
      "(epoch: 139, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.050 G_L1: 27.888 D_real: 0.003 D_fake: 0.163 \n",
      "(epoch: 139, iters: 400, time: 0.489, data: 0.002) G_GAN: 4.325 G_L1: 25.038 D_real: 0.035 D_fake: 0.038 \n",
      "End of epoch 139 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "(epoch: 140, iters: 100, time: 0.112, data: 0.281) G_GAN: 3.958 G_L1: 25.000 D_real: 0.024 D_fake: 0.062 \n",
      "(epoch: 140, iters: 200, time: 0.114, data: 0.002) G_GAN: 4.714 G_L1: 19.602 D_real: 0.502 D_fake: 0.012 \n",
      "(epoch: 140, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.079 G_L1: 23.624 D_real: 0.064 D_fake: 0.283 \n",
      "(epoch: 140, iters: 400, time: 0.509, data: 0.002) G_GAN: 3.358 G_L1: 22.226 D_real: 0.104 D_fake: 0.133 \n",
      "saving the model at the end of epoch 140, iters 56000\n",
      "End of epoch 140 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "(epoch: 141, iters: 100, time: 0.111, data: 0.289) G_GAN: 1.420 G_L1: 16.372 D_real: 0.691 D_fake: 0.065 \n",
      "(epoch: 141, iters: 200, time: 0.110, data: 0.002) G_GAN: 4.503 G_L1: 21.763 D_real: 0.064 D_fake: 0.017 \n",
      "(epoch: 141, iters: 300, time: 0.114, data: 0.002) G_GAN: 2.783 G_L1: 25.230 D_real: 0.014 D_fake: 0.571 \n",
      "(epoch: 141, iters: 400, time: 0.602, data: 0.002) G_GAN: 3.996 G_L1: 23.080 D_real: 0.026 D_fake: 0.046 \n",
      "End of epoch 141 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "(epoch: 142, iters: 100, time: 0.112, data: 0.281) G_GAN: 3.155 G_L1: 19.706 D_real: 0.089 D_fake: 0.096 \n",
      "(epoch: 142, iters: 200, time: 0.101, data: 0.002) G_GAN: 4.227 G_L1: 26.399 D_real: 0.007 D_fake: 0.588 \n",
      "(epoch: 142, iters: 300, time: 0.109, data: 0.002) G_GAN: 6.080 G_L1: 22.876 D_real: 0.144 D_fake: 0.004 \n",
      "(epoch: 142, iters: 400, time: 0.501, data: 0.002) G_GAN: 4.498 G_L1: 19.090 D_real: 0.326 D_fake: 0.009 \n",
      "End of epoch 142 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "(epoch: 143, iters: 100, time: 0.112, data: 0.269) G_GAN: 3.363 G_L1: 19.813 D_real: 0.092 D_fake: 0.069 \n",
      "(epoch: 143, iters: 200, time: 0.110, data: 0.002) G_GAN: 0.981 G_L1: 15.855 D_real: 1.138 D_fake: 0.033 \n",
      "(epoch: 143, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.988 G_L1: 25.541 D_real: 0.041 D_fake: 0.339 \n",
      "(epoch: 143, iters: 400, time: 0.486, data: 0.002) G_GAN: 3.056 G_L1: 17.269 D_real: 0.152 D_fake: 0.218 \n",
      "End of epoch 143 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "(epoch: 144, iters: 100, time: 0.111, data: 0.294) G_GAN: 2.670 G_L1: 19.687 D_real: 0.202 D_fake: 0.292 \n",
      "(epoch: 144, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.078 G_L1: 20.124 D_real: 0.022 D_fake: 0.152 \n",
      "(epoch: 144, iters: 300, time: 0.110, data: 0.002) G_GAN: 3.365 G_L1: 25.610 D_real: 0.114 D_fake: 0.420 \n",
      "(epoch: 144, iters: 400, time: 0.518, data: 0.002) G_GAN: 4.092 G_L1: 20.388 D_real: 0.669 D_fake: 0.009 \n",
      "End of epoch 144 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "(epoch: 145, iters: 100, time: 0.112, data: 0.304) G_GAN: 1.972 G_L1: 20.020 D_real: 0.661 D_fake: 0.057 \n",
      "(epoch: 145, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.777 G_L1: 20.446 D_real: 0.062 D_fake: 0.033 \n",
      "(epoch: 145, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.771 G_L1: 18.147 D_real: 0.477 D_fake: 0.030 \n",
      "(epoch: 145, iters: 400, time: 0.518, data: 0.002) G_GAN: 3.456 G_L1: 24.066 D_real: 0.042 D_fake: 0.186 \n",
      "saving the model at the end of epoch 145, iters 58000\n",
      "End of epoch 145 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "(epoch: 146, iters: 100, time: 0.112, data: 0.310) G_GAN: 4.176 G_L1: 22.681 D_real: 0.071 D_fake: 0.027 \n",
      "(epoch: 146, iters: 200, time: 0.114, data: 0.002) G_GAN: 4.241 G_L1: 26.512 D_real: 0.002 D_fake: 0.322 \n",
      "(epoch: 146, iters: 300, time: 0.113, data: 0.002) G_GAN: 4.044 G_L1: 26.001 D_real: 0.064 D_fake: 0.048 \n",
      "(epoch: 146, iters: 400, time: 0.603, data: 0.002) G_GAN: 5.485 G_L1: 17.824 D_real: 0.042 D_fake: 0.747 \n",
      "End of epoch 146 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "(epoch: 147, iters: 100, time: 0.114, data: 0.296) G_GAN: 4.440 G_L1: 20.872 D_real: 0.086 D_fake: 0.033 \n",
      "(epoch: 147, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.763 G_L1: 22.383 D_real: 0.172 D_fake: 0.028 \n",
      "(epoch: 147, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.531 G_L1: 28.099 D_real: 0.003 D_fake: 0.499 \n",
      "(epoch: 147, iters: 400, time: 0.511, data: 0.003) G_GAN: 7.353 G_L1: 21.537 D_real: 0.235 D_fake: 0.001 \n",
      "End of epoch 147 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "(epoch: 148, iters: 100, time: 0.114, data: 0.286) G_GAN: 4.227 G_L1: 16.074 D_real: 0.036 D_fake: 0.028 \n",
      "(epoch: 148, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.748 G_L1: 21.797 D_real: 0.081 D_fake: 0.049 \n",
      "(epoch: 148, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.713 G_L1: 21.826 D_real: 0.218 D_fake: 0.084 \n",
      "(epoch: 148, iters: 400, time: 0.523, data: 0.002) G_GAN: 3.175 G_L1: 16.816 D_real: 0.071 D_fake: 0.100 \n",
      "End of epoch 148 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "(epoch: 149, iters: 100, time: 0.115, data: 0.291) G_GAN: 3.784 G_L1: 22.170 D_real: 0.046 D_fake: 0.057 \n",
      "(epoch: 149, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.141 G_L1: 25.890 D_real: 0.134 D_fake: 0.107 \n",
      "(epoch: 149, iters: 300, time: 0.108, data: 0.002) G_GAN: 3.983 G_L1: 15.997 D_real: 0.049 D_fake: 0.304 \n",
      "(epoch: 149, iters: 400, time: 0.518, data: 0.002) G_GAN: 4.465 G_L1: 25.996 D_real: 0.011 D_fake: 0.075 \n",
      "End of epoch 149 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "(epoch: 150, iters: 100, time: 0.112, data: 0.281) G_GAN: 4.083 G_L1: 20.220 D_real: 0.161 D_fake: 0.055 \n",
      "(epoch: 150, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.850 G_L1: 22.595 D_real: 0.438 D_fake: 0.011 \n",
      "(epoch: 150, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.961 G_L1: 23.641 D_real: 0.127 D_fake: 0.067 \n",
      "(epoch: 150, iters: 400, time: 0.516, data: 0.002) G_GAN: 4.013 G_L1: 18.296 D_real: 0.094 D_fake: 0.028 \n",
      "saving the latest model (epoch 150, total_iters 60000)\n",
      "saving the model at the end of epoch 150, iters 60000\n",
      "End of epoch 150 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "(epoch: 151, iters: 100, time: 0.112, data: 0.294) G_GAN: 3.390 G_L1: 26.199 D_real: 0.001 D_fake: 0.311 \n",
      "(epoch: 151, iters: 200, time: 0.111, data: 0.002) G_GAN: 4.478 G_L1: 25.721 D_real: 0.001 D_fake: 0.040 \n",
      "(epoch: 151, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.357 G_L1: 25.600 D_real: 0.031 D_fake: 0.068 \n",
      "(epoch: 151, iters: 400, time: 0.595, data: 0.002) G_GAN: 3.961 G_L1: 19.289 D_real: 0.540 D_fake: 0.010 \n",
      "End of epoch 151 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "(epoch: 152, iters: 100, time: 0.115, data: 0.293) G_GAN: 4.208 G_L1: 19.255 D_real: 0.076 D_fake: 0.027 \n",
      "(epoch: 152, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.643 G_L1: 18.933 D_real: 0.065 D_fake: 0.144 \n",
      "(epoch: 152, iters: 300, time: 0.113, data: 0.002) G_GAN: 4.171 G_L1: 22.042 D_real: 0.047 D_fake: 0.034 \n",
      "(epoch: 152, iters: 400, time: 0.552, data: 0.002) G_GAN: 2.456 G_L1: 16.478 D_real: 0.447 D_fake: 0.060 \n",
      "End of epoch 152 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "(epoch: 153, iters: 100, time: 0.114, data: 0.296) G_GAN: 3.438 G_L1: 20.076 D_real: 0.044 D_fake: 0.071 \n",
      "(epoch: 153, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.129 G_L1: 23.594 D_real: 0.015 D_fake: 0.240 \n",
      "(epoch: 153, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.702 G_L1: 19.928 D_real: 0.027 D_fake: 0.078 \n",
      "(epoch: 153, iters: 400, time: 0.532, data: 0.002) G_GAN: 4.479 G_L1: 29.112 D_real: 0.002 D_fake: 0.036 \n",
      "End of epoch 153 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "(epoch: 154, iters: 100, time: 0.111, data: 0.304) G_GAN: 3.211 G_L1: 17.902 D_real: 0.114 D_fake: 0.153 \n",
      "(epoch: 154, iters: 200, time: 0.114, data: 0.002) G_GAN: 4.311 G_L1: 25.818 D_real: 0.001 D_fake: 0.088 \n",
      "(epoch: 154, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.757 G_L1: 20.224 D_real: 0.062 D_fake: 0.046 \n",
      "(epoch: 154, iters: 400, time: 0.534, data: 0.002) G_GAN: 3.497 G_L1: 14.571 D_real: 0.409 D_fake: 0.030 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 154 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "(epoch: 155, iters: 100, time: 0.112, data: 0.287) G_GAN: 2.018 G_L1: 20.463 D_real: 0.556 D_fake: 0.113 \n",
      "(epoch: 155, iters: 200, time: 0.112, data: 0.002) G_GAN: 1.456 G_L1: 14.864 D_real: 0.945 D_fake: 0.005 \n",
      "(epoch: 155, iters: 300, time: 0.114, data: 0.002) G_GAN: 4.725 G_L1: 24.255 D_real: 0.044 D_fake: 0.018 \n",
      "(epoch: 155, iters: 400, time: 0.534, data: 0.002) G_GAN: 4.114 G_L1: 24.856 D_real: 0.003 D_fake: 0.140 \n",
      "saving the model at the end of epoch 155, iters 62000\n",
      "End of epoch 155 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "(epoch: 156, iters: 100, time: 0.112, data: 0.284) G_GAN: 3.682 G_L1: 21.342 D_real: 0.113 D_fake: 0.051 \n",
      "(epoch: 156, iters: 200, time: 0.108, data: 0.002) G_GAN: 4.178 G_L1: 19.033 D_real: 0.148 D_fake: 0.029 \n",
      "(epoch: 156, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.610 G_L1: 19.606 D_real: 0.165 D_fake: 0.029 \n",
      "(epoch: 156, iters: 400, time: 0.602, data: 0.002) G_GAN: 3.324 G_L1: 16.205 D_real: 0.180 D_fake: 0.155 \n",
      "End of epoch 156 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "(epoch: 157, iters: 100, time: 0.110, data: 0.287) G_GAN: 3.537 G_L1: 16.450 D_real: 0.024 D_fake: 0.424 \n",
      "(epoch: 157, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.456 G_L1: 20.357 D_real: 0.105 D_fake: 0.067 \n",
      "(epoch: 157, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.480 G_L1: 14.792 D_real: 0.323 D_fake: 0.144 \n",
      "(epoch: 157, iters: 400, time: 0.536, data: 0.002) G_GAN: 2.487 G_L1: 16.642 D_real: 0.455 D_fake: 0.066 \n",
      "End of epoch 157 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "(epoch: 158, iters: 100, time: 0.111, data: 0.269) G_GAN: 1.404 G_L1: 21.501 D_real: 2.305 D_fake: 0.035 \n",
      "(epoch: 158, iters: 200, time: 0.111, data: 0.002) G_GAN: 4.313 G_L1: 22.141 D_real: 0.011 D_fake: 0.527 \n",
      "(epoch: 158, iters: 300, time: 0.111, data: 0.002) G_GAN: 4.582 G_L1: 17.438 D_real: 0.105 D_fake: 0.016 \n",
      "(epoch: 158, iters: 400, time: 0.532, data: 0.002) G_GAN: 4.506 G_L1: 16.517 D_real: 0.058 D_fake: 1.042 \n",
      "End of epoch 158 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "(epoch: 159, iters: 100, time: 0.112, data: 0.291) G_GAN: 3.089 G_L1: 17.681 D_real: 0.161 D_fake: 0.350 \n",
      "(epoch: 159, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.758 G_L1: 16.748 D_real: 0.061 D_fake: 0.331 \n",
      "(epoch: 159, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.605 G_L1: 18.202 D_real: 0.072 D_fake: 0.230 \n",
      "(epoch: 159, iters: 400, time: 0.542, data: 0.002) G_GAN: 3.933 G_L1: 22.869 D_real: 0.005 D_fake: 0.055 \n",
      "End of epoch 159 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "(epoch: 160, iters: 100, time: 0.112, data: 0.281) G_GAN: 3.206 G_L1: 21.257 D_real: 0.045 D_fake: 0.122 \n",
      "(epoch: 160, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.260 G_L1: 19.898 D_real: 0.001 D_fake: 0.227 \n",
      "(epoch: 160, iters: 300, time: 0.111, data: 0.002) G_GAN: 4.102 G_L1: 20.017 D_real: 0.006 D_fake: 0.047 \n",
      "(epoch: 160, iters: 400, time: 0.523, data: 0.002) G_GAN: 3.741 G_L1: 24.331 D_real: 0.012 D_fake: 0.079 \n",
      "saving the model at the end of epoch 160, iters 64000\n",
      "End of epoch 160 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "(epoch: 161, iters: 100, time: 0.112, data: 0.308) G_GAN: 2.867 G_L1: 18.694 D_real: 0.110 D_fake: 0.185 \n",
      "(epoch: 161, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.959 G_L1: 22.080 D_real: 0.079 D_fake: 0.046 \n",
      "(epoch: 161, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.865 G_L1: 20.213 D_real: 0.468 D_fake: 0.120 \n",
      "(epoch: 161, iters: 400, time: 0.688, data: 0.002) G_GAN: 3.464 G_L1: 17.232 D_real: 0.333 D_fake: 0.023 \n",
      "End of epoch 161 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "(epoch: 162, iters: 100, time: 0.112, data: 0.285) G_GAN: 3.209 G_L1: 23.873 D_real: 0.070 D_fake: 0.083 \n",
      "(epoch: 162, iters: 200, time: 0.111, data: 0.002) G_GAN: 4.411 G_L1: 20.465 D_real: 0.190 D_fake: 0.017 \n",
      "(epoch: 162, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.591 G_L1: 25.273 D_real: 0.010 D_fake: 0.114 \n",
      "(epoch: 162, iters: 400, time: 0.585, data: 0.002) G_GAN: 3.185 G_L1: 16.783 D_real: 0.053 D_fake: 0.380 \n",
      "End of epoch 162 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "(epoch: 163, iters: 100, time: 0.113, data: 0.286) G_GAN: 2.173 G_L1: 25.924 D_real: 0.346 D_fake: 0.206 \n",
      "(epoch: 163, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.724 G_L1: 19.393 D_real: 0.005 D_fake: 0.071 \n",
      "saving the latest model (epoch 163, total_iters 65000)\n",
      "(epoch: 163, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.732 G_L1: 25.118 D_real: 0.002 D_fake: 0.027 \n",
      "(epoch: 163, iters: 400, time: 0.531, data: 0.002) G_GAN: 2.813 G_L1: 29.469 D_real: 0.008 D_fake: 0.205 \n",
      "End of epoch 163 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "(epoch: 164, iters: 100, time: 0.112, data: 0.261) G_GAN: 3.974 G_L1: 24.872 D_real: 0.005 D_fake: 0.046 \n",
      "(epoch: 164, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.407 G_L1: 22.696 D_real: 0.401 D_fake: 0.020 \n",
      "(epoch: 164, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.223 G_L1: 26.853 D_real: 0.000 D_fake: 0.334 \n",
      "(epoch: 164, iters: 400, time: 0.531, data: 0.002) G_GAN: 4.682 G_L1: 14.883 D_real: 0.003 D_fake: 1.971 \n",
      "End of epoch 164 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "(epoch: 165, iters: 100, time: 0.113, data: 0.339) G_GAN: 3.484 G_L1: 20.751 D_real: 0.017 D_fake: 0.673 \n",
      "(epoch: 165, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.297 G_L1: 18.292 D_real: 0.018 D_fake: 0.337 \n",
      "(epoch: 165, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.280 G_L1: 20.190 D_real: 0.013 D_fake: 0.161 \n",
      "(epoch: 165, iters: 400, time: 0.652, data: 0.002) G_GAN: 3.061 G_L1: 24.715 D_real: 0.002 D_fake: 0.161 \n",
      "saving the model at the end of epoch 165, iters 66000\n",
      "End of epoch 165 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "(epoch: 166, iters: 100, time: 0.110, data: 0.310) G_GAN: 3.552 G_L1: 18.099 D_real: 0.214 D_fake: 0.043 \n",
      "(epoch: 166, iters: 200, time: 0.112, data: 0.002) G_GAN: 2.456 G_L1: 24.905 D_real: 0.134 D_fake: 0.365 \n",
      "(epoch: 166, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.600 G_L1: 21.701 D_real: 0.157 D_fake: 0.011 \n",
      "(epoch: 166, iters: 400, time: 0.538, data: 0.002) G_GAN: 5.217 G_L1: 20.790 D_real: 0.046 D_fake: 1.209 \n",
      "End of epoch 166 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "(epoch: 167, iters: 100, time: 0.113, data: 0.287) G_GAN: 2.801 G_L1: 18.113 D_real: 0.279 D_fake: 0.059 \n",
      "(epoch: 167, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.011 G_L1: 18.816 D_real: 0.320 D_fake: 0.064 \n",
      "(epoch: 167, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.220 G_L1: 18.809 D_real: 0.167 D_fake: 0.041 \n",
      "(epoch: 167, iters: 400, time: 0.552, data: 0.002) G_GAN: 3.935 G_L1: 19.178 D_real: 0.073 D_fake: 0.096 \n",
      "End of epoch 167 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "(epoch: 168, iters: 100, time: 0.113, data: 0.283) G_GAN: 2.471 G_L1: 24.781 D_real: 0.002 D_fake: 0.275 \n",
      "(epoch: 168, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.607 G_L1: 17.644 D_real: 0.053 D_fake: 0.026 \n",
      "(epoch: 168, iters: 300, time: 0.111, data: 0.002) G_GAN: 3.609 G_L1: 16.775 D_real: 0.075 D_fake: 0.041 \n",
      "(epoch: 168, iters: 400, time: 0.535, data: 0.002) G_GAN: 3.844 G_L1: 16.711 D_real: 0.247 D_fake: 0.024 \n",
      "End of epoch 168 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "(epoch: 169, iters: 100, time: 0.110, data: 0.288) G_GAN: 2.912 G_L1: 32.270 D_real: 0.036 D_fake: 0.176 \n",
      "(epoch: 169, iters: 200, time: 0.111, data: 0.002) G_GAN: 5.085 G_L1: 19.927 D_real: 0.147 D_fake: 0.008 \n",
      "(epoch: 169, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.931 G_L1: 21.973 D_real: 0.067 D_fake: 0.153 \n",
      "(epoch: 169, iters: 400, time: 0.558, data: 0.002) G_GAN: 5.956 G_L1: 23.398 D_real: 0.019 D_fake: 0.006 \n",
      "End of epoch 169 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "(epoch: 170, iters: 100, time: 0.112, data: 0.279) G_GAN: 3.511 G_L1: 17.977 D_real: 0.049 D_fake: 0.240 \n",
      "(epoch: 170, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.724 G_L1: 19.470 D_real: 0.117 D_fake: 0.039 \n",
      "(epoch: 170, iters: 300, time: 0.113, data: 0.002) G_GAN: 4.757 G_L1: 22.578 D_real: 0.452 D_fake: 0.010 \n",
      "(epoch: 170, iters: 400, time: 0.671, data: 0.002) G_GAN: 6.192 G_L1: 18.992 D_real: 0.032 D_fake: 0.004 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 170, iters 68000\n",
      "End of epoch 170 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "(epoch: 171, iters: 100, time: 0.095, data: 0.307) G_GAN: 3.003 G_L1: 20.136 D_real: 0.452 D_fake: 0.058 \n",
      "(epoch: 171, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.603 G_L1: 21.076 D_real: 0.032 D_fake: 0.095 \n",
      "(epoch: 171, iters: 300, time: 0.111, data: 0.002) G_GAN: 3.684 G_L1: 21.471 D_real: 0.133 D_fake: 0.027 \n",
      "(epoch: 171, iters: 400, time: 0.560, data: 0.002) G_GAN: 2.985 G_L1: 14.979 D_real: 0.051 D_fake: 0.192 \n",
      "End of epoch 171 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "(epoch: 172, iters: 100, time: 0.113, data: 0.282) G_GAN: 3.308 G_L1: 16.431 D_real: 0.096 D_fake: 0.086 \n",
      "(epoch: 172, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.785 G_L1: 23.130 D_real: 0.015 D_fake: 0.076 \n",
      "(epoch: 172, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.483 G_L1: 15.455 D_real: 0.382 D_fake: 0.086 \n",
      "(epoch: 172, iters: 400, time: 0.538, data: 0.002) G_GAN: 4.194 G_L1: 26.860 D_real: 0.066 D_fake: 0.028 \n",
      "End of epoch 172 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "(epoch: 173, iters: 100, time: 0.113, data: 0.292) G_GAN: 3.496 G_L1: 18.996 D_real: 0.286 D_fake: 0.031 \n",
      "(epoch: 173, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.981 G_L1: 24.010 D_real: 0.059 D_fake: 0.035 \n",
      "(epoch: 173, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.084 G_L1: 26.452 D_real: 0.025 D_fake: 0.116 \n",
      "(epoch: 173, iters: 400, time: 0.547, data: 0.002) G_GAN: 2.578 G_L1: 16.265 D_real: 0.228 D_fake: 0.056 \n",
      "End of epoch 173 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "(epoch: 174, iters: 100, time: 0.114, data: 0.288) G_GAN: 3.248 G_L1: 18.064 D_real: 0.206 D_fake: 0.044 \n",
      "(epoch: 174, iters: 200, time: 0.110, data: 0.002) G_GAN: 3.171 G_L1: 14.351 D_real: 0.020 D_fake: 0.086 \n",
      "(epoch: 174, iters: 300, time: 0.112, data: 0.002) G_GAN: 5.914 G_L1: 22.601 D_real: 0.053 D_fake: 0.004 \n",
      "(epoch: 174, iters: 400, time: 0.682, data: 0.002) G_GAN: 5.218 G_L1: 27.841 D_real: 0.003 D_fake: 0.020 \n",
      "End of epoch 174 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "(epoch: 175, iters: 100, time: 0.112, data: 0.273) G_GAN: 3.263 G_L1: 21.071 D_real: 0.021 D_fake: 0.098 \n",
      "(epoch: 175, iters: 200, time: 0.112, data: 0.002) G_GAN: 5.103 G_L1: 24.066 D_real: 0.007 D_fake: 0.010 \n",
      "(epoch: 175, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.930 G_L1: 19.631 D_real: 0.040 D_fake: 0.041 \n",
      "(epoch: 175, iters: 400, time: 0.598, data: 0.002) G_GAN: 3.524 G_L1: 23.334 D_real: 0.095 D_fake: 0.064 \n",
      "saving the latest model (epoch 175, total_iters 70000)\n",
      "saving the model at the end of epoch 175, iters 70000\n",
      "End of epoch 175 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "(epoch: 176, iters: 100, time: 0.112, data: 0.291) G_GAN: 3.936 G_L1: 20.743 D_real: 0.076 D_fake: 0.043 \n",
      "(epoch: 176, iters: 200, time: 0.110, data: 0.002) G_GAN: 3.811 G_L1: 22.630 D_real: 0.129 D_fake: 0.035 \n",
      "(epoch: 176, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.957 G_L1: 18.193 D_real: 0.103 D_fake: 0.055 \n",
      "(epoch: 176, iters: 400, time: 0.555, data: 0.002) G_GAN: 3.928 G_L1: 23.742 D_real: 0.859 D_fake: 0.018 \n",
      "End of epoch 176 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n",
      "(epoch: 177, iters: 100, time: 0.112, data: 0.308) G_GAN: 3.716 G_L1: 19.327 D_real: 0.017 D_fake: 0.071 \n",
      "(epoch: 177, iters: 200, time: 0.113, data: 0.002) G_GAN: 4.206 G_L1: 18.688 D_real: 0.026 D_fake: 0.038 \n",
      "(epoch: 177, iters: 300, time: 0.106, data: 0.002) G_GAN: 2.593 G_L1: 23.259 D_real: 0.126 D_fake: 0.525 \n",
      "(epoch: 177, iters: 400, time: 0.588, data: 0.002) G_GAN: 3.989 G_L1: 20.880 D_real: 0.034 D_fake: 0.034 \n",
      "End of epoch 177 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "(epoch: 178, iters: 100, time: 0.113, data: 0.288) G_GAN: 3.054 G_L1: 18.905 D_real: 0.058 D_fake: 0.247 \n",
      "(epoch: 178, iters: 200, time: 0.111, data: 0.002) G_GAN: 4.272 G_L1: 24.702 D_real: 0.012 D_fake: 0.043 \n",
      "(epoch: 178, iters: 300, time: 0.114, data: 0.002) G_GAN: 3.537 G_L1: 20.845 D_real: 0.823 D_fake: 0.012 \n",
      "(epoch: 178, iters: 400, time: 0.653, data: 0.002) G_GAN: 2.634 G_L1: 16.049 D_real: 0.130 D_fake: 0.106 \n",
      "End of epoch 178 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n",
      "(epoch: 179, iters: 100, time: 0.112, data: 0.285) G_GAN: 5.708 G_L1: 19.131 D_real: 0.094 D_fake: 0.007 \n",
      "(epoch: 179, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.934 G_L1: 21.358 D_real: 0.014 D_fake: 0.041 \n",
      "(epoch: 179, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.741 G_L1: 16.500 D_real: 0.334 D_fake: 0.008 \n",
      "(epoch: 179, iters: 400, time: 0.561, data: 0.002) G_GAN: 2.638 G_L1: 17.821 D_real: 0.087 D_fake: 0.205 \n",
      "End of epoch 179 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "(epoch: 180, iters: 100, time: 0.111, data: 0.284) G_GAN: 3.325 G_L1: 14.792 D_real: 0.033 D_fake: 0.090 \n",
      "(epoch: 180, iters: 200, time: 0.112, data: 0.002) G_GAN: 5.043 G_L1: 28.649 D_real: 0.025 D_fake: 0.016 \n",
      "(epoch: 180, iters: 300, time: 0.114, data: 0.002) G_GAN: 4.191 G_L1: 20.149 D_real: 0.053 D_fake: 0.039 \n",
      "(epoch: 180, iters: 400, time: 0.582, data: 0.002) G_GAN: 3.168 G_L1: 26.054 D_real: 0.014 D_fake: 0.176 \n",
      "saving the model at the end of epoch 180, iters 72000\n",
      "End of epoch 180 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "(epoch: 181, iters: 100, time: 0.113, data: 0.308) G_GAN: 3.360 G_L1: 19.567 D_real: 0.138 D_fake: 0.055 \n",
      "(epoch: 181, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.299 G_L1: 18.641 D_real: 0.035 D_fake: 0.095 \n",
      "(epoch: 181, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.919 G_L1: 22.630 D_real: 0.126 D_fake: 0.106 \n",
      "(epoch: 181, iters: 400, time: 0.585, data: 0.002) G_GAN: 2.497 G_L1: 17.404 D_real: 0.090 D_fake: 0.259 \n",
      "End of epoch 181 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "(epoch: 182, iters: 100, time: 0.112, data: 0.302) G_GAN: 2.933 G_L1: 19.394 D_real: 0.301 D_fake: 0.070 \n",
      "(epoch: 182, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.412 G_L1: 16.311 D_real: 0.377 D_fake: 0.094 \n",
      "(epoch: 182, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.676 G_L1: 19.323 D_real: 0.242 D_fake: 0.135 \n",
      "(epoch: 182, iters: 400, time: 0.697, data: 0.002) G_GAN: 2.617 G_L1: 19.958 D_real: 0.052 D_fake: 0.197 \n",
      "End of epoch 182 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "(epoch: 183, iters: 100, time: 0.112, data: 0.290) G_GAN: 3.878 G_L1: 18.708 D_real: 0.070 D_fake: 0.039 \n",
      "(epoch: 183, iters: 200, time: 0.105, data: 0.002) G_GAN: 7.032 G_L1: 18.972 D_real: 0.161 D_fake: 0.001 \n",
      "(epoch: 183, iters: 300, time: 0.114, data: 0.002) G_GAN: 2.767 G_L1: 19.713 D_real: 0.361 D_fake: 0.115 \n",
      "(epoch: 183, iters: 400, time: 0.577, data: 0.002) G_GAN: 4.004 G_L1: 22.266 D_real: 0.025 D_fake: 0.038 \n",
      "End of epoch 183 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "(epoch: 184, iters: 100, time: 0.113, data: 0.291) G_GAN: 4.921 G_L1: 20.296 D_real: 0.018 D_fake: 0.016 \n",
      "(epoch: 184, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.983 G_L1: 15.668 D_real: 0.337 D_fake: 0.049 \n",
      "(epoch: 184, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.886 G_L1: 24.161 D_real: 0.133 D_fake: 0.032 \n",
      "(epoch: 184, iters: 400, time: 0.586, data: 0.002) G_GAN: 3.965 G_L1: 19.711 D_real: 0.105 D_fake: 0.029 \n",
      "End of epoch 184 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "(epoch: 185, iters: 100, time: 0.111, data: 0.282) G_GAN: 2.582 G_L1: 17.094 D_real: 0.044 D_fake: 0.330 \n",
      "(epoch: 185, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.662 G_L1: 26.364 D_real: 0.036 D_fake: 0.023 \n",
      "(epoch: 185, iters: 300, time: 0.113, data: 0.002) G_GAN: 2.526 G_L1: 18.704 D_real: 0.062 D_fake: 0.264 \n",
      "(epoch: 185, iters: 400, time: 0.594, data: 0.002) G_GAN: 3.013 G_L1: 25.576 D_real: 0.000 D_fake: 0.446 \n",
      "saving the model at the end of epoch 185, iters 74000\n",
      "End of epoch 185 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "(epoch: 186, iters: 100, time: 0.111, data: 0.315) G_GAN: 3.670 G_L1: 14.369 D_real: 0.103 D_fake: 0.060 \n",
      "(epoch: 186, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.772 G_L1: 18.036 D_real: 0.123 D_fake: 0.034 \n",
      "(epoch: 186, iters: 300, time: 0.115, data: 0.002) G_GAN: 2.826 G_L1: 19.349 D_real: 0.114 D_fake: 0.085 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 186, iters: 400, time: 0.685, data: 0.002) G_GAN: 5.270 G_L1: 21.976 D_real: 0.026 D_fake: 0.010 \n",
      "End of epoch 186 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "(epoch: 187, iters: 100, time: 0.113, data: 0.290) G_GAN: 3.962 G_L1: 14.149 D_real: 0.163 D_fake: 0.021 \n",
      "(epoch: 187, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.862 G_L1: 20.071 D_real: 1.083 D_fake: 0.012 \n",
      "(epoch: 187, iters: 300, time: 0.111, data: 0.002) G_GAN: 2.909 G_L1: 23.085 D_real: 0.092 D_fake: 0.132 \n",
      "(epoch: 187, iters: 400, time: 0.587, data: 0.002) G_GAN: 4.250 G_L1: 21.779 D_real: 0.010 D_fake: 0.041 \n",
      "End of epoch 187 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "(epoch: 188, iters: 100, time: 0.113, data: 0.279) G_GAN: 2.527 G_L1: 21.129 D_real: 0.302 D_fake: 0.115 \n",
      "(epoch: 188, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.803 G_L1: 20.255 D_real: 0.067 D_fake: 0.047 \n",
      "saving the latest model (epoch 188, total_iters 75000)\n",
      "(epoch: 188, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.726 G_L1: 23.398 D_real: 0.004 D_fake: 0.056 \n",
      "(epoch: 188, iters: 400, time: 0.586, data: 0.002) G_GAN: 2.305 G_L1: 20.714 D_real: 0.072 D_fake: 0.428 \n",
      "End of epoch 188 / 200 \t Time Taken: 30 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "(epoch: 189, iters: 100, time: 0.113, data: 0.324) G_GAN: 4.408 G_L1: 16.761 D_real: 0.071 D_fake: 0.016 \n",
      "(epoch: 189, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.967 G_L1: 13.163 D_real: 0.424 D_fake: 0.024 \n",
      "(epoch: 189, iters: 300, time: 0.115, data: 0.002) G_GAN: 3.161 G_L1: 19.387 D_real: 0.025 D_fake: 0.124 \n",
      "(epoch: 189, iters: 400, time: 0.628, data: 0.002) G_GAN: 3.004 G_L1: 14.701 D_real: 0.012 D_fake: 0.127 \n",
      "End of epoch 189 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 100, time: 0.113, data: 0.287) G_GAN: 2.927 G_L1: 12.280 D_real: 0.422 D_fake: 0.054 \n",
      "(epoch: 190, iters: 200, time: 0.114, data: 0.002) G_GAN: 3.716 G_L1: 18.500 D_real: 0.134 D_fake: 0.039 \n",
      "(epoch: 190, iters: 300, time: 0.113, data: 0.002) G_GAN: 3.668 G_L1: 24.703 D_real: 0.132 D_fake: 0.047 \n",
      "(epoch: 190, iters: 400, time: 0.695, data: 0.002) G_GAN: 2.949 G_L1: 24.562 D_real: 0.166 D_fake: 0.112 \n",
      "saving the model at the end of epoch 190, iters 76000\n",
      "End of epoch 190 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "(epoch: 191, iters: 100, time: 0.111, data: 0.296) G_GAN: 1.585 G_L1: 18.611 D_real: 0.096 D_fake: 1.522 \n",
      "(epoch: 191, iters: 200, time: 0.111, data: 0.002) G_GAN: 2.631 G_L1: 19.555 D_real: 0.106 D_fake: 0.135 \n",
      "(epoch: 191, iters: 300, time: 0.111, data: 0.002) G_GAN: 5.381 G_L1: 20.374 D_real: 0.010 D_fake: 0.010 \n",
      "(epoch: 191, iters: 400, time: 0.594, data: 0.002) G_GAN: 4.141 G_L1: 31.837 D_real: 0.001 D_fake: 0.039 \n",
      "End of epoch 191 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "(epoch: 192, iters: 100, time: 0.114, data: 0.270) G_GAN: 1.985 G_L1: 24.074 D_real: 0.315 D_fake: 0.333 \n",
      "(epoch: 192, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.597 G_L1: 19.015 D_real: 0.145 D_fake: 0.036 \n",
      "(epoch: 192, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.893 G_L1: 17.643 D_real: 0.074 D_fake: 0.130 \n",
      "(epoch: 192, iters: 400, time: 0.595, data: 0.002) G_GAN: 4.374 G_L1: 22.611 D_real: 0.004 D_fake: 0.026 \n",
      "End of epoch 192 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 100, time: 0.111, data: 0.275) G_GAN: 3.073 G_L1: 15.104 D_real: 0.020 D_fake: 0.110 \n",
      "(epoch: 193, iters: 200, time: 0.112, data: 0.002) G_GAN: 4.480 G_L1: 18.002 D_real: 0.060 D_fake: 0.025 \n",
      "(epoch: 193, iters: 300, time: 0.112, data: 0.002) G_GAN: 2.700 G_L1: 20.639 D_real: 0.007 D_fake: 0.168 \n",
      "(epoch: 193, iters: 400, time: 0.603, data: 0.002) G_GAN: 2.265 G_L1: 23.554 D_real: 0.074 D_fake: 0.248 \n",
      "End of epoch 193 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "(epoch: 194, iters: 100, time: 0.113, data: 0.290) G_GAN: 2.887 G_L1: 23.596 D_real: 0.067 D_fake: 0.123 \n",
      "(epoch: 194, iters: 200, time: 0.101, data: 0.002) G_GAN: 2.902 G_L1: 20.985 D_real: 0.091 D_fake: 0.102 \n",
      "(epoch: 194, iters: 300, time: 0.107, data: 0.002) G_GAN: 3.281 G_L1: 20.565 D_real: 0.024 D_fake: 0.088 \n",
      "(epoch: 194, iters: 400, time: 0.737, data: 0.002) G_GAN: 3.184 G_L1: 12.613 D_real: 0.019 D_fake: 0.115 \n",
      "End of epoch 194 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "(epoch: 195, iters: 100, time: 0.114, data: 0.283) G_GAN: 4.012 G_L1: 15.705 D_real: 0.234 D_fake: 0.026 \n",
      "(epoch: 195, iters: 200, time: 0.111, data: 0.002) G_GAN: 3.492 G_L1: 17.384 D_real: 0.003 D_fake: 0.062 \n",
      "(epoch: 195, iters: 300, time: 0.115, data: 0.002) G_GAN: 4.297 G_L1: 16.031 D_real: 0.036 D_fake: 0.028 \n",
      "(epoch: 195, iters: 400, time: 0.627, data: 0.002) G_GAN: 3.534 G_L1: 18.878 D_real: 0.037 D_fake: 0.064 \n",
      "saving the model at the end of epoch 195, iters 78000\n",
      "End of epoch 195 / 200 \t Time Taken: 31 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "(epoch: 196, iters: 100, time: 0.111, data: 0.294) G_GAN: 4.040 G_L1: 24.553 D_real: 0.034 D_fake: 0.032 \n",
      "(epoch: 196, iters: 200, time: 0.113, data: 0.002) G_GAN: 3.911 G_L1: 22.203 D_real: 0.009 D_fake: 0.040 \n",
      "(epoch: 196, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.750 G_L1: 17.707 D_real: 0.087 D_fake: 0.040 \n",
      "(epoch: 196, iters: 400, time: 0.627, data: 0.002) G_GAN: 4.215 G_L1: 20.798 D_real: 0.119 D_fake: 0.029 \n",
      "End of epoch 196 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "(epoch: 197, iters: 100, time: 0.114, data: 0.282) G_GAN: 3.959 G_L1: 20.845 D_real: 0.101 D_fake: 0.046 \n",
      "(epoch: 197, iters: 200, time: 0.112, data: 0.002) G_GAN: 3.647 G_L1: 21.988 D_real: 0.059 D_fake: 0.063 \n",
      "(epoch: 197, iters: 300, time: 0.111, data: 0.002) G_GAN: 1.755 G_L1: 19.126 D_real: 0.086 D_fake: 0.396 \n",
      "(epoch: 197, iters: 400, time: 0.637, data: 0.002) G_GAN: 4.843 G_L1: 23.921 D_real: 0.011 D_fake: 0.018 \n",
      "End of epoch 197 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "(epoch: 198, iters: 100, time: 0.112, data: 0.293) G_GAN: 4.415 G_L1: 19.113 D_real: 0.028 D_fake: 0.023 \n",
      "(epoch: 198, iters: 200, time: 0.113, data: 0.002) G_GAN: 4.661 G_L1: 22.388 D_real: 0.036 D_fake: 0.019 \n",
      "(epoch: 198, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.931 G_L1: 29.784 D_real: 0.002 D_fake: 0.049 \n",
      "(epoch: 198, iters: 400, time: 0.744, data: 0.002) G_GAN: 4.415 G_L1: 20.547 D_real: 0.047 D_fake: 0.022 \n",
      "End of epoch 198 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "(epoch: 199, iters: 100, time: 0.113, data: 0.278) G_GAN: 2.815 G_L1: 23.964 D_real: 0.125 D_fake: 0.139 \n",
      "(epoch: 199, iters: 200, time: 0.113, data: 0.002) G_GAN: 1.850 G_L1: 20.971 D_real: 0.105 D_fake: 0.291 \n",
      "(epoch: 199, iters: 300, time: 0.112, data: 0.002) G_GAN: 3.927 G_L1: 20.320 D_real: 0.168 D_fake: 0.033 \n",
      "(epoch: 199, iters: 400, time: 0.588, data: 0.002) G_GAN: 3.577 G_L1: 22.975 D_real: 0.042 D_fake: 0.054 \n",
      "End of epoch 199 / 200 \t Time Taken: 27 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 100, time: 0.112, data: 0.302) G_GAN: 3.172 G_L1: 24.296 D_real: 0.045 D_fake: 0.080 \n",
      "(epoch: 200, iters: 200, time: 0.113, data: 0.002) G_GAN: 2.917 G_L1: 18.297 D_real: 0.091 D_fake: 0.094 \n",
      "(epoch: 200, iters: 300, time: 0.112, data: 0.002) G_GAN: 4.136 G_L1: 25.524 D_real: 0.300 D_fake: 0.035 \n",
      "(epoch: 200, iters: 400, time: 0.626, data: 0.002) G_GAN: 2.722 G_L1: 24.906 D_real: 0.081 D_fake: 0.127 \n",
      "saving the latest model (epoch 200, total_iters 80000)\n",
      "saving the model at the end of epoch 200, iters 80000\n",
      "End of epoch 200 / 200 \t Time Taken: 34 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA --display_id -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mey7o6j-0368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facades_label2photo_pretrained\tfacades_pix2pix\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/facades            \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: facades_label2photo_pretrained\t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: True                          \t[default: False]\n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/facades_label2photo_pretrained/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: "
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained --use_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
