{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fe2110",
   "metadata": {},
   "source": [
    "# ResNet 2개층만 미세조정 모델 ( model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6cd748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n",
      "94781440/94765736 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Pre-trained ResNet50 모델을 불러옵니다.\n",
    "base_model_2 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) #최상위 분류 레이어를 제외하고, 기본적인 특성 추출 부분만 불러옵니다.\n",
    "base_model_2.trainable = False           # 모든 레이어를 동결\n",
    "for layer in base_model_2.layers[-2:]:  # 마지막 2개 레이어만 동결 해제\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94748465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            6150        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 25,692,038\n",
      "Trainable params: 2,104,326\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = base_model_2.output\n",
    "x = GlobalAveragePooling2D()(x)    # 경량화와 빠른 학습, 적은 파라미터로 처리\n",
    "#x = Flatten()(base_model.output)  # 많은 파라미터 계산, 고급 모델에서 정밀한 분류시 유리\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(6, activation='softmax')(x) # 해파리를 6개의 클래스로 분류\n",
    "model_2 = Model(base_model_2.input, outputs)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc6bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    optimizer='adam',   # Adam 최적화 알고리즘 (일반적으로 잘 동작)\n",
    "    loss='sparse_categorical_crossentropy',  # 타겟의 출력이 원-핫 인코딩된 형태가 아니라 정수형 라벨로 되어 있음. 다중 클래스 분류를 위한 손실 함수\n",
    "    metrics=['accuracy']  # 모델의 정확도를 평가 지표로 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ef7912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 45s 105ms/step - loss: 2.1138 - accuracy: 0.1650 - val_loss: 1.9165 - val_accuracy: 0.1633\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.91648, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 2.0036 - accuracy: 0.1752 - val_loss: 1.9319 - val_accuracy: 0.1990\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.91648\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.8559 - accuracy: 0.1664 - val_loss: 1.8302 - val_accuracy: 0.2245\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.91648 to 1.83023, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.8011 - accuracy: 0.1971 - val_loss: 1.7717 - val_accuracy: 0.1939\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.83023 to 1.77167, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.8026 - accuracy: 0.2146 - val_loss: 1.8734 - val_accuracy: 0.2143\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.77167\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.8301 - accuracy: 0.2117 - val_loss: 1.8477 - val_accuracy: 0.1990\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.77167\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.8286 - accuracy: 0.1825 - val_loss: 1.7909 - val_accuracy: 0.1888\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.77167\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 6s 67ms/step - loss: 1.7845 - accuracy: 0.1971 - val_loss: 1.7537 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.77167 to 1.75369, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7780 - accuracy: 0.2029 - val_loss: 1.7761 - val_accuracy: 0.1939\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.75369\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7937 - accuracy: 0.1912 - val_loss: 1.7590 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.75369\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7809 - accuracy: 0.1927 - val_loss: 1.7791 - val_accuracy: 0.1684\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.75369\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7773 - accuracy: 0.1766 - val_loss: 1.7503 - val_accuracy: 0.2296\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.75369 to 1.75031, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7762 - accuracy: 0.2044 - val_loss: 1.7756 - val_accuracy: 0.2551\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.75031\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7714 - accuracy: 0.2292 - val_loss: 1.8086 - val_accuracy: 0.1684\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.75031\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7753 - accuracy: 0.2058 - val_loss: 1.7619 - val_accuracy: 0.1837\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.75031\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7777 - accuracy: 0.1883 - val_loss: 1.7504 - val_accuracy: 0.2398\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.75031\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7695 - accuracy: 0.2219 - val_loss: 1.7518 - val_accuracy: 0.2398\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.75031\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7642 - accuracy: 0.2292 - val_loss: 1.7474 - val_accuracy: 0.2143\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.75031 to 1.74741, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7707 - accuracy: 0.2044 - val_loss: 1.7660 - val_accuracy: 0.1939\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.74741\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7585 - accuracy: 0.2307 - val_loss: 1.7843 - val_accuracy: 0.1837\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.74741\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7609 - accuracy: 0.2088 - val_loss: 1.7409 - val_accuracy: 0.2755\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.74741 to 1.74091, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7552 - accuracy: 0.2131 - val_loss: 1.7415 - val_accuracy: 0.2551\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.74091\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7560 - accuracy: 0.2292 - val_loss: 1.7439 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.74091\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7475 - accuracy: 0.2350 - val_loss: 1.7363 - val_accuracy: 0.2245\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.74091 to 1.73628, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7678 - accuracy: 0.2146 - val_loss: 1.7488 - val_accuracy: 0.1990\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.73628\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7414 - accuracy: 0.2423 - val_loss: 1.7450 - val_accuracy: 0.2653\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.73628\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7490 - accuracy: 0.2423 - val_loss: 1.7480 - val_accuracy: 0.2449\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.73628\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7408 - accuracy: 0.2496 - val_loss: 1.7358 - val_accuracy: 0.2704\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.73628 to 1.73585, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7336 - accuracy: 0.2321 - val_loss: 1.7233 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.73585 to 1.72330, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7278 - accuracy: 0.2365 - val_loss: 1.7194 - val_accuracy: 0.2347\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.72330 to 1.71940, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7338 - accuracy: 0.2190 - val_loss: 1.7231 - val_accuracy: 0.2653\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.71940\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7169 - accuracy: 0.2686 - val_loss: 1.7242 - val_accuracy: 0.2551\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.71940\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7302 - accuracy: 0.2263 - val_loss: 1.7089 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.71940 to 1.70885, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7193 - accuracy: 0.2715 - val_loss: 1.7340 - val_accuracy: 0.2245\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.70885\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7481 - accuracy: 0.2248 - val_loss: 1.7203 - val_accuracy: 0.2398\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.70885\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7197 - accuracy: 0.2759 - val_loss: 1.7130 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.70885\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 7s 65ms/step - loss: 1.7505 - accuracy: 0.2204 - val_loss: 1.7266 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.70885\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.7259 - accuracy: 0.2599 - val_loss: 1.7093 - val_accuracy: 0.2296\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.70885\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7203 - accuracy: 0.2555 - val_loss: 1.7019 - val_accuracy: 0.2806\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.70885 to 1.70186, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7022 - accuracy: 0.2745 - val_loss: 1.7187 - val_accuracy: 0.2551\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.70186\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7057 - accuracy: 0.2686 - val_loss: 1.7449 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.70186\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.7055 - accuracy: 0.2511 - val_loss: 1.6904 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.70186 to 1.69037, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6792 - accuracy: 0.2803 - val_loss: 1.6862 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.69037 to 1.68618, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6826 - accuracy: 0.2920 - val_loss: 1.7180 - val_accuracy: 0.2449\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.68618\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6804 - accuracy: 0.2978 - val_loss: 1.7160 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.68618\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6822 - accuracy: 0.2745 - val_loss: 1.6831 - val_accuracy: 0.2704\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.68618 to 1.68312, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6731 - accuracy: 0.2701 - val_loss: 1.6914 - val_accuracy: 0.2653\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.68312\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6955 - accuracy: 0.2613 - val_loss: 1.6753 - val_accuracy: 0.3061\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.68312 to 1.67531, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6801 - accuracy: 0.2788 - val_loss: 1.7915 - val_accuracy: 0.2143\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.67531\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6838 - accuracy: 0.2774 - val_loss: 1.6798 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.67531\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6658 - accuracy: 0.2788 - val_loss: 1.6650 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.67531 to 1.66501, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6591 - accuracy: 0.3036 - val_loss: 1.6992 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.66501\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6742 - accuracy: 0.2818 - val_loss: 1.7296 - val_accuracy: 0.2449\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.66501\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6830 - accuracy: 0.2759 - val_loss: 1.6564 - val_accuracy: 0.3061\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.66501 to 1.65642, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6550 - accuracy: 0.3036 - val_loss: 1.7023 - val_accuracy: 0.2653\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.65642\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6449 - accuracy: 0.2774 - val_loss: 1.7099 - val_accuracy: 0.2551\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.65642\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6680 - accuracy: 0.3007 - val_loss: 1.7277 - val_accuracy: 0.2704\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.65642\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6577 - accuracy: 0.3066 - val_loss: 1.6567 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.65642\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6286 - accuracy: 0.3197 - val_loss: 1.6461 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.65642 to 1.64608, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6456 - accuracy: 0.3007 - val_loss: 1.6704 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.64608\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6404 - accuracy: 0.2934 - val_loss: 1.6665 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.64608\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6244 - accuracy: 0.3153 - val_loss: 1.6584 - val_accuracy: 0.3418\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.64608\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6233 - accuracy: 0.3153 - val_loss: 1.6542 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.64608\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6167 - accuracy: 0.3401 - val_loss: 1.6897 - val_accuracy: 0.2755\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.64608\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 6s 66ms/step - loss: 1.6335 - accuracy: 0.3022 - val_loss: 1.6369 - val_accuracy: 0.3061\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.64608 to 1.63685, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6077 - accuracy: 0.3036 - val_loss: 1.6696 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.63685\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6193 - accuracy: 0.3182 - val_loss: 1.6467 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.63685\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6132 - accuracy: 0.3270 - val_loss: 1.7273 - val_accuracy: 0.2806\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.63685\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6277 - accuracy: 0.3080 - val_loss: 1.7758 - val_accuracy: 0.2653\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.63685\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6508 - accuracy: 0.3036 - val_loss: 1.8037 - val_accuracy: 0.2398\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.63685\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6344 - accuracy: 0.3299 - val_loss: 1.7197 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.63685\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6135 - accuracy: 0.3153 - val_loss: 1.6785 - val_accuracy: 0.3367\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.63685\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5917 - accuracy: 0.3635 - val_loss: 1.6465 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.63685\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6204 - accuracy: 0.3328 - val_loss: 1.6980 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.63685\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6201 - accuracy: 0.3168 - val_loss: 1.6409 - val_accuracy: 0.3112\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.63685\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6295 - accuracy: 0.2993 - val_loss: 1.6781 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.63685\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.5962 - accuracy: 0.3270 - val_loss: 1.6376 - val_accuracy: 0.3112\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.63685\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6665 - accuracy: 0.2876 - val_loss: 1.7246 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.63685\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6176 - accuracy: 0.3080 - val_loss: 1.7474 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.63685\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5745 - accuracy: 0.3401 - val_loss: 1.6362 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.63685 to 1.63624, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.5988 - accuracy: 0.3474 - val_loss: 1.7560 - val_accuracy: 0.2398\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.63624\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6294 - accuracy: 0.3022 - val_loss: 1.6479 - val_accuracy: 0.3367\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.63624\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.5515 - accuracy: 0.3723 - val_loss: 1.6248 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.63624 to 1.62484, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6029 - accuracy: 0.3182 - val_loss: 1.7914 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.62484\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.6135 - accuracy: 0.3139 - val_loss: 1.6357 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.62484\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5702 - accuracy: 0.3431 - val_loss: 1.6811 - val_accuracy: 0.3316\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.62484\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 6s 66ms/step - loss: 1.6054 - accuracy: 0.3358 - val_loss: 1.6427 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.62484\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5822 - accuracy: 0.3197 - val_loss: 1.6845 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.62484\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.5816 - accuracy: 0.3416 - val_loss: 1.6934 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.62484\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6051 - accuracy: 0.3445 - val_loss: 1.7021 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.62484\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5967 - accuracy: 0.3489 - val_loss: 1.6411 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.62484\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.5747 - accuracy: 0.3387 - val_loss: 1.6688 - val_accuracy: 0.3469\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.62484\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6146 - accuracy: 0.3270 - val_loss: 1.7272 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.62484\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.6007 - accuracy: 0.3182 - val_loss: 1.6752 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.62484\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5900 - accuracy: 0.3226 - val_loss: 1.6982 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.62484\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.5929 - accuracy: 0.3153 - val_loss: 1.6200 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.62484 to 1.61995, saving model to ResNet_model.keras_3\n",
      "INFO:tensorflow:Assets written to: ResNet_model.keras_3/assets\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5790 - accuracy: 0.3460 - val_loss: 1.6833 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.61995\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 6s 65ms/step - loss: 1.5553 - accuracy: 0.3591 - val_loss: 1.6210 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.61995\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5786 - accuracy: 0.3314 - val_loss: 1.6728 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.61995\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 6s 64ms/step - loss: 1.5420 - accuracy: 0.3606 - val_loss: 1.6463 - val_accuracy: 0.3112\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.61995\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    'ResNet_model.keras_3',  # 모델 저장 경로\n",
    "    monitor='val_loss',    # 검증 손실을 기준으로 저장\n",
    "    save_best_only=True,  # 가장 좋은 모델만 저장\n",
    "    verbose=1)             # 저장 시 메시지 출력\n",
    "]\n",
    "\n",
    "history = model_2.fit(\n",
    "    train_ds,  # 훈련 데이터\n",
    "    epochs=100,\n",
    "    validation_data=val_ds,  # 검증 데이터\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d77f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 1s - loss: 1.5335 - accuracy: 0.3469\n",
      "Test Loss: 1.5335311889648438\n",
      "Test Accuracy: 0.3469387888908386\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_2.evaluate(test_ds, verbose=2)\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feee1209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 2s - loss: 1.5300 - accuracy: 0.4184\n",
      "Test Loss: 1.5299738645553589\n",
      "Test Accuracy: 0.4183673560619354\n"
     ]
    }
   ],
   "source": [
    "model3 = tf.keras.models.load_model('ResNet_model.keras_3')\n",
    "\n",
    "test_loss, test_accuracy = model3.evaluate(test_ds, verbose=2)\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
